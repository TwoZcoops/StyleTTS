Setting up StyleTTS from scratch in VS Code (Windows) using Conda & Jupyter NotebookThis guide provides a comprehensive walkthrough for setting up StyleTTS from scratch in VS Code (Windows) using Conda and Jupyter Notebook, while ensuring Phonemizer and eSpeak NG are correctly configured. This detailed guide will equip you with the knowledge and tools to get started with StyleTTS, a powerful text-to-speech (TTS) model with an impressive ability to generate natural and expressive speech 1.Setting up the Conda EnvironmentBefore we dive into StyleTTS, let's set up our development environment. We'll use Conda, a popular package and environment manager, to create an isolated environment for our project. Using a Conda environment offers several benefits, such as dependency isolation and reproducibility, ensuring a consistent and reliable setup 2.
Create and activate a new Conda environment in VS Code: Open a terminal in VS Code and run the following command, replacing <ENV_NAME> with your preferred environment name (e.g., styletts-env) and <VERSION> with your desired Python version (e.g., 3.9): conda create --name <ENV_NAME> python=<VERSION> 3 If you don't specify a Python version, Conda will install the latest version from the available channels. Activate the newly created environment using the command: conda activate <ENV_NAME> 4 You should see the environment name in parentheses at the beginning of your terminal prompt, indicating that the environment is active.
Installing the Required PackagesWith our Conda environment activated, we can now install the necessary packages for StyleTTS.
Install PyTorch, torchaudio, librosa, and Jupyter: These packages are fundamental for audio processing, deep learning tasks, and interactive coding in StyleTTS. Use the following command to install them: conda install pytorch torchvision torchaudio -c pytorch librosa jupyter 5 This command installs PyTorch with CUDA support. If you don't have a CUDA-enabled GPU, you can install the CPU-only version of PyTorch.
Install Phonemizer and eSpeak NG: Phonemizer is a library that converts text into phonemes (the basic units of sound in language), and eSpeak NG is a speech synthesizer that we'll use as the backend for Phonemizer. Install them using Conda: conda install -c conda-forge phonemizer espeak-ng 8
Configuring Phonemizer to use eSpeak NGTo ensure StyleTTS works correctly, we need to configure Phonemizer to use eSpeak NG as its backend. This involves setting specific environment variables that point to the eSpeak NG library and executable files.
Set environment variables:

Go to the Windows Control Panel and search for "environment variables".
Click on "Edit the system environment variables".
In the System Properties window, click on "Environment Variables...".
Under "System variables", click "New..." to add a new environment variable.
For the first variable, set the "Variable name" to PHONEMIZER_ESPEAK_LIBRARY and the "Variable value" to the path to the eSpeak NG library file, which is typically C:\Program Files\eSpeak NG\libespeak-ng.dll.
Click "OK" to save the variable.
Repeat the process to add another system variable with the "Variable name" set to PHONEMIZER_ESPEAK_PATH and the "Variable value" set to C:\Program Files\eSpeak NG\espeak-ng.exe.
Click "OK" on all the open windows to close the environment variables settings.


Verify the configuration: To verify that Phonemizer is correctly configured, open a Jupyter Notebook in VS Code and run the following code:
Pythonfrom phonemizer import phonemize

text = "Hello, world!"
phonemes = phonemize(text, language='en-us', backend='espeak')
print(phonemes)
If the setup is successful, this code will print the phonemic transcription of "Hello, world!" generated by eSpeak NG7.Installing StyleTTSNow that our environment is ready, let's install StyleTTS.
Clone the StyleTTS repository: Clone the StyleTTS repository from GitHub using the following command in your terminal: git clone https://github.com/yl4579/StyleTTS-VC.git 10 This will download the StyleTTS code to your local machine.
Install additional dependencies: Navigate to the StyleTTS directory using cd StyleTTS-VC and install the remaining dependencies using pip: pip install -r requirements.txt 11 This command installs all the necessary packages listed in the requirements.txt file.
Dataset PreparationBefore you can start using StyleTTS, you need to download and prepare the VCTK dataset. This dataset contains speech data that StyleTTS uses for training and inference.
Download the VCTK dataset from the official source.
Extract the downloaded dataset to a location on your computer.
Downsample all the audio files in the wav48_silence_trimmed folder to 24 kHz. You can use audio editing software like Audacity to do this.
Rename the downsampled folder to wav24_silence_trimmed.
This preprocessing is necessary because the vocoder, text aligner, and pitch extractor are pre-trained on 24 kHz data 10.Downloading Pre-trained ModelsStyleTTS requires pre-trained models to function. You can download these models from the links provided in the StyleTTS repository 1. Make sure to download the models that are compatible with your chosen version of StyleTTS. Unzip the downloaded models to the Models and Vocoder folders within the StyleTTS-VC directory 13.Testing the SetupTo test if your StyleTTS installation is working correctly, you can use the following code snippet:Pythonimport replicate

# Load environment variables
model_id = "adirik/styletts2:53fd5081feae9440974d1ef9cae83bf7af5fe18be1646343f37e559f5f80a613"

# Text to be synthesized
text = "This is a demo to test StyleTTS."

# Generate speech
output = replicate.run(
    model_id,
    input={"text": text}
)

# Print the output URL
print(output)
This code uses the replicate library to interact with the StyleTTS model hosted on Replicate. It takes the text "This is a demo to test StyleTTS" as input and generates an audio file with the synthesized speech. The output of the code is a URL that you can open in your browser to listen to the generated audio 14.ConclusionBy following these steps, you've successfully set up StyleTTS from scratch in VS Code (Windows) using Conda and Jupyter Notebook. You've also configured Phonemizer and eSpeak NG, installed the necessary packages, prepared the dataset, and downloaded the pre-trained models. With this comprehensive setup, you're now ready to explore the capabilities of StyleTTS and generate natural and expressive speech for various applications.