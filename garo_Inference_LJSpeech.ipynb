{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c16ca3fd-ca0a-4f24-ac55-a827bba684d5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# StyleTTS Demo (LJSpeech)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6108384d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a400d1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\garym\\OneDrive\\Scripts\\GM_Alienware\\workspaces\\StyleTTS\n",
      "Python Path: ['c:\\\\Users\\\\garym\\\\OneDrive\\\\Scripts\\\\GM_Alienware\\\\workspaces\\\\StyleTTS', 'c:\\\\Users\\\\garym\\\\OneDrive\\\\Scripts\\\\GM_Alienware\\\\opt\\\\Conda\\\\envs\\\\styletts\\\\python39.zip', 'c:\\\\Users\\\\garym\\\\OneDrive\\\\Scripts\\\\GM_Alienware\\\\opt\\\\Conda\\\\envs\\\\styletts\\\\DLLs', 'c:\\\\Users\\\\garym\\\\OneDrive\\\\Scripts\\\\GM_Alienware\\\\opt\\\\Conda\\\\envs\\\\styletts\\\\lib', 'c:\\\\Users\\\\garym\\\\OneDrive\\\\Scripts\\\\GM_Alienware\\\\opt\\\\Conda\\\\envs\\\\styletts', '', 'c:\\\\Users\\\\garym\\\\OneDrive\\\\Scripts\\\\GM_Alienware\\\\opt\\\\Conda\\\\envs\\\\styletts\\\\lib\\\\site-packages', 'c:\\\\Users\\\\garym\\\\OneDrive\\\\Scripts\\\\GM_Alienware\\\\opt\\\\Conda\\\\envs\\\\styletts\\\\lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\garym\\\\OneDrive\\\\Scripts\\\\GM_Alienware\\\\opt\\\\Conda\\\\envs\\\\styletts\\\\lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\garym\\\\OneDrive\\\\Scripts\\\\GM_Alienware\\\\opt\\\\Conda\\\\envs\\\\styletts\\\\lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add current directory explicitly\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "# Print to verify Python sees the correct directory\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "print(\"Python Path:\", sys.path)\n",
    "\n",
    "# Now import\n",
    "from models import *  \n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "958a9f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports successful! All modules are loaded.\n"
     ]
    }
   ],
   "source": [
    "# Imports and setup for garo_Inference_LJSpeech.ipynb\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.getcwd())  # Ensure the working directory is first in sys.path\n",
    "\n",
    "import random\n",
    "import yaml\n",
    "from munch import Munch\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "import librosa\n",
    "from nltk.tokenize import word_tokenize\n",
    "from models import *  # This should now work correctly\n",
    "from utils import *\n",
    "# %matplotlib inline # Keep or remove as needed\n",
    "print(\"✅ Imports successful! All modules are loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a3ddcc8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ eSpeak is properly detected by Phonemizer!\n"
     ]
    }
   ],
   "source": [
    "# This is mostly for verification, not setup.  The environment\n",
    "# variables should be set *before* launching the notebook.\n",
    "from phonemizer.backend import EspeakBackend\n",
    "\n",
    "try:\n",
    "    backend = EspeakBackend(\"en-us\")\n",
    "    print(\"✅ eSpeak is properly detected by Phonemizer!\")\n",
    "except Exception as e:\n",
    "    print(\"❌ eSpeak detection failed!\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbdc04c0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a173af4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Text Cleaner is working! Processed Output: [24, 47, 54, 54, 57, 3, 16, 65, 57, 60, 54, 46, 5]\n"
     ]
    }
   ],
   "source": [
    "_pad = \"$\"\n",
    "_punctuation = ';:,.!?¡¿—…\"«»“” '\n",
    "_letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "_letters_ipa = \"ɑɐɒæɓʙβɔɕçɗɖðʤəɘɚɛɜɝɞɟʄɡɠɢʛɦɧħɥʜɨɪʝɭɬɫɮʟɱɯɰŋɳɲɴøɵɸθœɶʘɹɺɾɻʀʁɽʂʃʈʧʉʊʋⱱʌɣɤʍχʎʏʑʐʒʔʡʕʢǀǁǂǃˈˌːˑʼʴʰʱʲʷˠˤ˞↓↑→↗↘'̩'ᵻ\"\n",
    "\n",
    "# Export all symbols:\n",
    "symbols = [_pad] + list(_punctuation) + list(_letters) + list(_letters_ipa)\n",
    "\n",
    "dicts = {symbols[i]: i for i in range(len(symbols))}\n",
    "\n",
    "class TextCleaner:\n",
    "    def __init__(self, dummy=None):\n",
    "        self.word_index_dictionary = dicts\n",
    "\n",
    "    def __call__(self, text):\n",
    "        indexes = []\n",
    "        for char in text:\n",
    "            try:\n",
    "                indexes.append(self.word_index_dictionary[char])\n",
    "            except KeyError:\n",
    "                print(f\"⚠️ Warning: Character '{char}' not found in dictionary!\")\n",
    "        return indexes\n",
    "\n",
    "# Initialize the text cleaner\n",
    "textclenaer = TextCleaner()\n",
    "\n",
    "# ✅ Test it immediately\n",
    "test_text = \"Hello, world!\"\n",
    "cleaned_text = textclenaer(test_text)\n",
    "\n",
    "print(\"✅ Text Cleaner is working! Processed Output:\", cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00ee05e1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessing test successful! Mel Shape: torch.Size([1, 80, 81])\n"
     ]
    }
   ],
   "source": [
    "# Define Mel Spectrogram transformation\n",
    "to_mel = torchaudio.transforms.MelSpectrogram(\n",
    "    n_mels=80, n_fft=2048, win_length=1200, hop_length=300\n",
    ")\n",
    "mean, std = -4, 4\n",
    "\n",
    "# Function to create a mask for padding\n",
    "def length_to_mask(lengths):\n",
    "    mask = torch.arange(lengths.max()).unsqueeze(0).expand(lengths.shape[0], -1).type_as(lengths)\n",
    "    mask = torch.gt(mask + 1, lengths.unsqueeze(1))\n",
    "    return mask\n",
    "\n",
    "# Preprocess waveform into Mel spectrogram\n",
    "def preprocess(wave):\n",
    "    wave_tensor = torch.from_numpy(wave).float()\n",
    "    mel_tensor = to_mel(wave_tensor)\n",
    "    mel_tensor = (torch.log(1e-5 + mel_tensor.unsqueeze(0)) - mean) / std\n",
    "    return mel_tensor\n",
    "\n",
    "# Compute style embeddings for reference audio files\n",
    "def compute_style(ref_dicts, model):\n",
    "    reference_embeddings = {}\n",
    "    for key, path in ref_dicts.items():\n",
    "        wave, sr = librosa.load(path, sr=24000)\n",
    "        audio, index = librosa.effects.trim(wave, top_db=30)\n",
    "        if sr != 24000:\n",
    "            audio = librosa.resample(audio, sr, 24000)\n",
    "        mel_tensor = preprocess(audio).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            ref = model.style_encoder(mel_tensor.unsqueeze(1))\n",
    "        reference_embeddings[key] = (ref.squeeze(1), audio)\n",
    "    \n",
    "    return reference_embeddings\n",
    "\n",
    "# ✅ Test the preprocess function with random noise\n",
    "test_wave = np.random.randn(24000)  # 1 second of fake audio\n",
    "mel_output = preprocess(test_wave)\n",
    "\n",
    "print(\"✅ Preprocessing test successful! Mel Shape:\", mel_output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9cecbe",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64fc4c0f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Phonemizer test successful! Output: ['həlˈoʊ, wˈɜːld! ']\n"
     ]
    }
   ],
   "source": [
    "# load phonemizer\n",
    "import phonemizer\n",
    "global_phonemizer = phonemizer.backend.EspeakBackend(language='en-us', preserve_punctuation=True,  with_stress=True)\n",
    "test_text = \"Hello, world!\"\n",
    "phonemes = global_phonemizer.phonemize([test_text])\n",
    "\n",
    "print(\"✅ Phonemizer test successful! Output:\", phonemes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54cfbe48",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully imported vocoder!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\garym\\OneDrive\\Scripts\\GM_Alienware\\opt\\Conda\\envs\\styletts\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 'Vocoder\\g_00750000'\n",
      "Complete.\n",
      "Removing weight norm...\n"
     ]
    }
   ],
   "source": [
    "# load hifi-gan\n",
    "import sys\n",
    "sys.path.insert(0, \"../Demo/hifi-gan\")\n",
    "sys.path.append(r\"C:\\Users\\garym\\OneDrive\\Scripts\\GM_Alienware\\workspaces\\StyleTTS\\Demo\\hifi-gan\")\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import torch\n",
    "from scipy.io.wavfile import write\n",
    "from attrdict import AttrDict\n",
    "from vocoder import Generator\n",
    "print(\"✅ Successfully imported vocoder!\")\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "\n",
    "h = None\n",
    "\n",
    "def load_checkpoint(filepath, device):\n",
    "    assert os.path.isfile(filepath)\n",
    "    print(\"Loading '{}'\".format(filepath))\n",
    "    checkpoint_dict = torch.load(filepath, map_location=device, weights_only=True)\n",
    "    print(\"Complete.\")\n",
    "    return checkpoint_dict\n",
    "\n",
    "def scan_checkpoint(cp_dir, prefix):\n",
    "    pattern = os.path.join(cp_dir, prefix + '*')\n",
    "    cp_list = glob.glob(pattern)\n",
    "    if len(cp_list) == 0:\n",
    "        return ''\n",
    "    return sorted(cp_list)[-1]\n",
    "\n",
    "cp_g = scan_checkpoint(\"Vocoder/\", 'g_')\n",
    "\n",
    "config_file = os.path.join(os.path.split(cp_g)[0], 'config.json')\n",
    "with open(config_file) as f:\n",
    "    data = f.read()\n",
    "json_config = json.loads(data)\n",
    "h = AttrDict(json_config)\n",
    "\n",
    "device = torch.device(device)\n",
    "generator = Generator(h).to(device)\n",
    "\n",
    "state_dict_g = load_checkpoint(cp_g, device)\n",
    "generator.load_state_dict(state_dict_g['generator'])\n",
    "generator.eval()\n",
    "generator.remove_weight_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02fb18a6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['hidden_dim', 'n_token', 'style_dim', 'n_layer', 'dim_in', 'max_conv_dim', 'n_mels', 'dropout'])\n",
      "⚠️ Warning: 'decoder' is missing in config! Using default settings.\n",
      "⚠️ Warning: 'max_dur' is missing in config! Using default value: 1 (to match pretrained model).\n",
      "⚠️ Warning: 'multispeaker' is missing in config! Using default value: False.\n",
      "⚠️ Warning: 'diffusion' is missing in config! Using default with transformer and embedding_mask_proba.\n",
      "⚠️ Warning: 'slm' is missing in config! Using default values.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\garym\\AppData\\Local\\Temp\\ipykernel_17516\\889889123.py:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  params = torch.load(model_path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictor loaded\n",
      "decoder loaded\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Decoder:\n\tMissing key(s) in state_dict: \"decode.3.conv1x1.weight_g\", \"decode.3.conv1x1.weight_v\", \"decode.3.pool.bias\", \"decode.3.pool.weight_g\", \"decode.3.pool.weight_v\", \"encode.conv1.bias\", \"encode.conv1.weight_g\", \"encode.conv1.weight_v\", \"encode.conv2.bias\", \"encode.conv2.weight_g\", \"encode.conv2.weight_v\", \"encode.norm1.fc.weight\", \"encode.norm1.fc.bias\", \"encode.norm2.fc.weight\", \"encode.norm2.fc.bias\", \"encode.conv1x1.weight_g\", \"encode.conv1x1.weight_v\", \"F0_conv.bias\", \"F0_conv.weight_g\", \"F0_conv.weight_v\", \"N_conv.bias\", \"N_conv.weight_g\", \"N_conv.weight_v\", \"generator.m_source.l_linear.weight\", \"generator.m_source.l_linear.bias\", \"generator.noise_convs.0.weight\", \"generator.noise_convs.0.bias\", \"generator.noise_convs.1.weight\", \"generator.noise_convs.1.bias\", \"generator.noise_convs.2.weight\", \"generator.noise_convs.2.bias\", \"generator.noise_convs.3.weight\", \"generator.noise_convs.3.bias\", \"generator.ups.0.bias\", \"generator.ups.0.weight_g\", \"generator.ups.0.weight_v\", \"generator.ups.1.bias\", \"generator.ups.1.weight_g\", \"generator.ups.1.weight_v\", \"generator.ups.2.bias\", \"generator.ups.2.weight_g\", \"generator.ups.2.weight_v\", \"generator.ups.3.bias\", \"generator.ups.3.weight_g\", \"generator.ups.3.weight_v\", \"generator.noise_res.0.convs1.0.bias\", \"generator.noise_res.0.convs1.0.weight_g\", \"generator.noise_res.0.convs1.0.weight_v\", \"generator.noise_res.0.convs1.1.bias\", \"generator.noise_res.0.convs1.1.weight_g\", \"generator.noise_res.0.convs1.1.weight_v\", \"generator.noise_res.0.convs1.2.bias\", \"generator.noise_res.0.convs1.2.weight_g\", \"generator.noise_res.0.convs1.2.weight_v\", \"generator.noise_res.0.convs2.0.bias\", \"generator.noise_res.0.convs2.0.weight_g\", \"generator.noise_res.0.convs2.0.weight_v\", \"generator.noise_res.0.convs2.1.bias\", \"generator.noise_res.0.convs2.1.weight_g\", \"generator.noise_res.0.convs2.1.weight_v\", \"generator.noise_res.0.convs2.2.bias\", \"generator.noise_res.0.convs2.2.weight_g\", \"generator.noise_res.0.convs2.2.weight_v\", \"generator.noise_res.0.adain1.0.fc.weight\", \"generator.noise_res.0.adain1.0.fc.bias\", \"generator.noise_res.0.adain1.1.fc.weight\", \"generator.noise_res.0.adain1.1.fc.bias\", \"generator.noise_res.0.adain1.2.fc.weight\", \"generator.noise_res.0.adain1.2.fc.bias\", \"generator.noise_res.0.adain2.0.fc.weight\", \"generator.noise_res.0.adain2.0.fc.bias\", \"generator.noise_res.0.adain2.1.fc.weight\", \"generator.noise_res.0.adain2.1.fc.bias\", \"generator.noise_res.0.adain2.2.fc.weight\", \"generator.noise_res.0.adain2.2.fc.bias\", \"generator.noise_res.0.alpha1.0\", \"generator.noise_res.0.alpha1.1\", \"generator.noise_res.0.alpha1.2\", \"generator.noise_res.0.alpha2.0\", \"generator.noise_res.0.alpha2.1\", \"generator.noise_res.0.alpha2.2\", \"generator.noise_res.1.convs1.0.bias\", \"generator.noise_res.1.convs1.0.weight_g\", \"generator.noise_res.1.convs1.0.weight_v\", \"generator.noise_res.1.convs1.1.bias\", \"generator.noise_res.1.convs1.1.weight_g\", \"generator.noise_res.1.convs1.1.weight_v\", \"generator.noise_res.1.convs1.2.bias\", \"generator.noise_res.1.convs1.2.weight_g\", \"generator.noise_res.1.convs1.2.weight_v\", \"generator.noise_res.1.convs2.0.bias\", \"generator.noise_res.1.convs2.0.weight_g\", \"generator.noise_res.1.convs2.0.weight_v\", \"generator.noise_res.1.convs2.1.bias\", \"generator.noise_res.1.convs2.1.weight_g\", \"generator.noise_res.1.convs2.1.weight_v\", \"generator.noise_res.1.convs2.2.bias\", \"generator.noise_res.1.convs2.2.weight_g\", \"generator.noise_res.1.convs2.2.weight_v\", \"generator.noise_res.1.adain1.0.fc.weight\", \"generator.noise_res.1.adain1.0.fc.bias\", \"generator.noise_res.1.adain1.1.fc.weight\", \"generator.noise_res.1.adain1.1.fc.bias\", \"generator.noise_res.1.adain1.2.fc.weight\", \"generator.noise_res.1.adain1.2.fc.bias\", \"generator.noise_res.1.adain2.0.fc.weight\", \"generator.noise_res.1.adain2.0.fc.bias\", \"generator.noise_res.1.adain2.1.fc.weight\", \"generator.noise_res.1.adain2.1.fc.bias\", \"generator.noise_res.1.adain2.2.fc.weight\", \"generator.noise_res.1.adain2.2.fc.bias\", \"generator.noise_res.1.alpha1.0\", \"generator.noise_res.1.alpha1.1\", \"generator.noise_res.1.alpha1.2\", \"generator.noise_res.1.alpha2.0\", \"generator.noise_res.1.alpha2.1\", \"generator.noise_res.1.alpha2.2\", \"generator.noise_res.2.convs1.0.bias\", \"generator.noise_res.2.convs1.0.weight_g\", \"generator.noise_res.2.convs1.0.weight_v\", \"generator.noise_res.2.convs1.1.bias\", \"generator.noise_res.2.convs1.1.weight_g\", \"generator.noise_res.2.convs1.1.weight_v\", \"generator.noise_res.2.convs1.2.bias\", \"generator.noise_res.2.convs1.2.weight_g\", \"generator.noise_res.2.convs1.2.weight_v\", \"generator.noise_res.2.convs2.0.bias\", \"generator.noise_res.2.convs2.0.weight_g\", \"generator.noise_res.2.convs2.0.weight_v\", \"generator.noise_res.2.convs2.1.bias\", \"generator.noise_res.2.convs2.1.weight_g\", \"generator.noise_res.2.convs2.1.weight_v\", \"generator.noise_res.2.convs2.2.bias\", \"generator.noise_res.2.convs2.2.weight_g\", \"generator.noise_res.2.convs2.2.weight_v\", \"generator.noise_res.2.adain1.0.fc.weight\", \"generator.noise_res.2.adain1.0.fc.bias\", \"generator.noise_res.2.adain1.1.fc.weight\", \"generator.noise_res.2.adain1.1.fc.bias\", \"generator.noise_res.2.adain1.2.fc.weight\", \"generator.noise_res.2.adain1.2.fc.bias\", \"generator.noise_res.2.adain2.0.fc.weight\", \"generator.noise_res.2.adain2.0.fc.bias\", \"generator.noise_res.2.adain2.1.fc.weight\", \"generator.noise_res.2.adain2.1.fc.bias\", \"generator.noise_res.2.adain2.2.fc.weight\", \"generator.noise_res.2.adain2.2.fc.bias\", \"generator.noise_res.2.alpha1.0\", \"generator.noise_res.2.alpha1.1\", \"generator.noise_res.2.alpha1.2\", \"generator.noise_res.2.alpha2.0\", \"generator.noise_res.2.alpha2.1\", \"generator.noise_res.2.alpha2.2\", \"generator.noise_res.3.convs1.0.bias\", \"generator.noise_res.3.convs1.0.weight_g\", \"generator.noise_res.3.convs1.0.weight_v\", \"generator.noise_res.3.convs1.1.bias\", \"generator.noise_res.3.convs1.1.weight_g\", \"generator.noise_res.3.convs1.1.weight_v\", \"generator.noise_res.3.convs1.2.bias\", \"generator.noise_res.3.convs1.2.weight_g\", \"generator.noise_res.3.convs1.2.weight_v\", \"generator.noise_res.3.convs2.0.bias\", \"generator.noise_res.3.convs2.0.weight_g\", \"generator.noise_res.3.convs2.0.weight_v\", \"generator.noise_res.3.convs2.1.bias\", \"generator.noise_res.3.convs2.1.weight_g\", \"generator.noise_res.3.convs2.1.weight_v\", \"generator.noise_res.3.convs2.2.bias\", \"generator.noise_res.3.convs2.2.weight_g\", \"generator.noise_res.3.convs2.2.weight_v\", \"generator.noise_res.3.adain1.0.fc.weight\", \"generator.noise_res.3.adain1.0.fc.bias\", \"generator.noise_res.3.adain1.1.fc.weight\", \"generator.noise_res.3.adain1.1.fc.bias\", \"generator.noise_res.3.adain1.2.fc.weight\", \"generator.noise_res.3.adain1.2.fc.bias\", \"generator.noise_res.3.adain2.0.fc.weight\", \"generator.noise_res.3.adain2.0.fc.bias\", \"generator.noise_res.3.adain2.1.fc.weight\", \"generator.noise_res.3.adain2.1.fc.bias\", \"generator.noise_res.3.adain2.2.fc.weight\", \"generator.noise_res.3.adain2.2.fc.bias\", \"generator.noise_res.3.alpha1.0\", \"generator.noise_res.3.alpha1.1\", \"generator.noise_res.3.alpha1.2\", \"generator.noise_res.3.alpha2.0\", \"generator.noise_res.3.alpha2.1\", \"generator.noise_res.3.alpha2.2\", \"generator.resblocks.0.convs1.0.bias\", \"generator.resblocks.0.convs1.0.weight_g\", \"generator.resblocks.0.convs1.0.weight_v\", \"generator.resblocks.0.convs1.1.bias\", \"generator.resblocks.0.convs1.1.weight_g\", \"generator.resblocks.0.convs1.1.weight_v\", \"generator.resblocks.0.convs1.2.bias\", \"generator.resblocks.0.convs1.2.weight_g\", \"generator.resblocks.0.convs1.2.weight_v\", \"generator.resblocks.0.convs2.0.bias\", \"generator.resblocks.0.convs2.0.weight_g\", \"generator.resblocks.0.convs2.0.weight_v\", \"generator.resblocks.0.convs2.1.bias\", \"generator.resblocks.0.convs2.1.weight_g\", \"generator.resblocks.0.convs2.1.weight_v\", \"generator.resblocks.0.convs2.2.bias\", \"generator.resblocks.0.convs2.2.weight_g\", \"generator.resblocks.0.convs2.2.weight_v\", \"generator.resblocks.0.adain1.0.fc.weight\", \"generator.resblocks.0.adain1.0.fc.bias\", \"generator.resblocks.0.adain1.1.fc.weight\", \"generator.resblocks.0.adain1.1.fc.bias\", \"generator.resblocks.0.adain1.2.fc.weight\", \"generator.resblocks.0.adain1.2.fc.bias\", \"generator.resblocks.0.adain2.0.fc.weight\", \"generator.resblocks.0.adain2.0.fc.bias\", \"generator.resblocks.0.adain2.1.fc.weight\", \"generator.resblocks.0.adain2.1.fc.bias\", \"generator.resblocks.0.adain2.2.fc.weight\", \"generator.resblocks.0.adain2.2.fc.bias\", \"generator.resblocks.0.alpha1.0\", \"generator.resblocks.0.alpha1.1\", \"generator.resblocks.0.alpha1.2\", \"generator.resblocks.0.alpha2.0\", \"generator.resblocks.0.alpha2.1\", \"generator.resblocks.0.alpha2.2\", \"generator.resblocks.1.convs1.0.bias\", \"generator.resblocks.1.convs1.0.weight_g\", \"generator.resblocks.1.convs1.0.weight_v\", \"generator.resblocks.1.convs1.1.bias\", \"generator.resblocks.1.convs1.1.weight_g\", \"generator.resblocks.1.convs1.1.weight_v\", \"generator.resblocks.1.convs1.2.bias\", \"generator.resblocks.1.convs1.2.weight_g\", \"generator.resblocks.1.convs1.2.weight_v\", \"generator.resblocks.1.convs2.0.bias\", \"generator.resblocks.1.convs2.0.weight_g\", \"generator.resblocks.1.convs2.0.weight_v\", \"generator.resblocks.1.convs2.1.bias\", \"generator.resblocks.1.convs2.1.weight_g\", \"generator.resblocks.1.convs2.1.weight_v\", \"generator.resblocks.1.convs2.2.bias\", \"generator.resblocks.1.convs2.2.weight_g\", \"generator.resblocks.1.convs2.2.weight_v\", \"generator.resblocks.1.adain1.0.fc.weight\", \"generator.resblocks.1.adain1.0.fc.bias\", \"generator.resblocks.1.adain1.1.fc.weight\", \"generator.resblocks.1.adain1.1.fc.bias\", \"generator.resblocks.1.adain1.2.fc.weight\", \"generator.resblocks.1.adain1.2.fc.bias\", \"generator.resblocks.1.adain2.0.fc.weight\", \"generator.resblocks.1.adain2.0.fc.bias\", \"generator.resblocks.1.adain2.1.fc.weight\", \"generator.resblocks.1.adain2.1.fc.bias\", \"generator.resblocks.1.adain2.2.fc.weight\", \"generator.resblocks.1.adain2.2.fc.bias\", \"generator.resblocks.1.alpha1.0\", \"generator.resblocks.1.alpha1.1\", \"generator.resblocks.1.alpha1.2\", \"generator.resblocks.1.alpha2.0\", \"generator.resblocks.1.alpha2.1\", \"generator.resblocks.1.alpha2.2\", \"generator.resblocks.2.convs1.0.bias\", \"generator.resblocks.2.convs1.0.weight_g\", \"generator.resblocks.2.convs1.0.weight_v\", \"generator.resblocks.2.convs1.1.bias\", \"generator.resblocks.2.convs1.1.weight_g\", \"generator.resblocks.2.convs1.1.weight_v\", \"generator.resblocks.2.convs1.2.bias\", \"generator.resblocks.2.convs1.2.weight_g\", \"generator.resblocks.2.convs1.2.weight_v\", \"generator.resblocks.2.convs2.0.bias\", \"generator.resblocks.2.convs2.0.weight_g\", \"generator.resblocks.2.convs2.0.weight_v\", \"generator.resblocks.2.convs2.1.bias\", \"generator.resblocks.2.convs2.1.weight_g\", \"generator.resblocks.2.convs2.1.weight_v\", \"generator.resblocks.2.convs2.2.bias\", \"generator.resblocks.2.convs2.2.weight_g\", \"generator.resblocks.2.convs2.2.weight_v\", \"generator.resblocks.2.adain1.0.fc.weight\", \"generator.resblocks.2.adain1.0.fc.bias\", \"generator.resblocks.2.adain1.1.fc.weight\", \"generator.resblocks.2.adain1.1.fc.bias\", \"generator.resblocks.2.adain1.2.fc.weight\", \"generator.resblocks.2.adain1.2.fc.bias\", \"generator.resblocks.2.adain2.0.fc.weight\", \"generator.resblocks.2.adain2.0.fc.bias\", \"generator.resblocks.2.adain2.1.fc.weight\", \"generator.resblocks.2.adain2.1.fc.bias\", \"generator.resblocks.2.adain2.2.fc.weight\", \"generator.resblocks.2.adain2.2.fc.bias\", \"generator.resblocks.2.alpha1.0\", \"generator.resblocks.2.alpha1.1\", \"generator.resblocks.2.alpha1.2\", \"generator.resblocks.2.alpha2.0\", \"generator.resblocks.2.alpha2.1\", \"generator.resblocks.2.alpha2.2\", \"generator.resblocks.3.convs1.0.bias\", \"generator.resblocks.3.convs1.0.weight_g\", \"generator.resblocks.3.convs1.0.weight_v\", \"generator.resblocks.3.convs1.1.bias\", \"generator.resblocks.3.convs1.1.weight_g\", \"generator.resblocks.3.convs1.1.weight_v\", \"generator.resblocks.3.convs1.2.bias\", \"generator.resblocks.3.convs1.2.weight_g\", \"generator.resblocks.3.convs1.2.weight_v\", \"generator.resblocks.3.convs2.0.bias\", \"generator.resblocks.3.convs2.0.weight_g\", \"generator.resblocks.3.convs2.0.weight_v\", \"generator.resblocks.3.convs2.1.bias\", \"generator.resblocks.3.convs2.1.weight_g\", \"generator.resblocks.3.convs2.1.weight_v\", \"generator.resblocks.3.convs2.2.bias\", \"generator.resblocks.3.convs2.2.weight_g\", \"generator.resblocks.3.convs2.2.weight_v\", \"generator.resblocks.3.adain1.0.fc.weight\", \"generator.resblocks.3.adain1.0.fc.bias\", \"generator.resblocks.3.adain1.1.fc.weight\", \"generator.resblocks.3.adain1.1.fc.bias\", \"generator.resblocks.3.adain1.2.fc.weight\", \"generator.resblocks.3.adain1.2.fc.bias\", \"generator.resblocks.3.adain2.0.fc.weight\", \"generator.resblocks.3.adain2.0.fc.bias\", \"generator.resblocks.3.adain2.1.fc.weight\", \"generator.resblocks.3.adain2.1.fc.bias\", \"generator.resblocks.3.adain2.2.fc.weight\", \"generator.resblocks.3.adain2.2.fc.bias\", \"generator.resblocks.3.alpha1.0\", \"generator.resblocks.3.alpha1.1\", \"generator.resblocks.3.alpha1.2\", \"generator.resblocks.3.alpha2.0\", \"generator.resblocks.3.alpha2.1\", \"generator.resblocks.3.alpha2.2\", \"generator.resblocks.4.convs1.0.bias\", \"generator.resblocks.4.convs1.0.weight_g\", \"generator.resblocks.4.convs1.0.weight_v\", \"generator.resblocks.4.convs1.1.bias\", \"generator.resblocks.4.convs1.1.weight_g\", \"generator.resblocks.4.convs1.1.weight_v\", \"generator.resblocks.4.convs1.2.bias\", \"generator.resblocks.4.convs1.2.weight_g\", \"generator.resblocks.4.convs1.2.weight_v\", \"generator.resblocks.4.convs2.0.bias\", \"generator.resblocks.4.convs2.0.weight_g\", \"generator.resblocks.4.convs2.0.weight_v\", \"generator.resblocks.4.convs2.1.bias\", \"generator.resblocks.4.convs2.1.weight_g\", \"generator.resblocks.4.convs2.1.weight_v\", \"generator.resblocks.4.convs2.2.bias\", \"generator.resblocks.4.convs2.2.weight_g\", \"generator.resblocks.4.convs2.2.weight_v\", \"generator.resblocks.4.adain1.0.fc.weight\", \"generator.resblocks.4.adain1.0.fc.bias\", \"generator.resblocks.4.adain1.1.fc.weight\", \"generator.resblocks.4.adain1.1.fc.bias\", \"generator.resblocks.4.adain1.2.fc.weight\", \"generator.resblocks.4.adain1.2.fc.bias\", \"generator.resblocks.4.adain2.0.fc.weight\", \"generator.resblocks.4.adain2.0.fc.bias\", \"generator.resblocks.4.adain2.1.fc.weight\", \"generator.resblocks.4.adain2.1.fc.bias\", \"generator.resblocks.4.adain2.2.fc.weight\", \"generator.resblocks.4.adain2.2.fc.bias\", \"generator.resblocks.4.alpha1.0\", \"generator.resblocks.4.alpha1.1\", \"generator.resblocks.4.alpha1.2\", \"generator.resblocks.4.alpha2.0\", \"generator.resblocks.4.alpha2.1\", \"generator.resblocks.4.alpha2.2\", \"generator.resblocks.5.convs1.0.bias\", \"generator.resblocks.5.convs1.0.weight_g\", \"generator.resblocks.5.convs1.0.weight_v\", \"generator.resblocks.5.convs1.1.bias\", \"generator.resblocks.5.convs1.1.weight_g\", \"generator.resblocks.5.convs1.1.weight_v\", \"generator.resblocks.5.convs1.2.bias\", \"generator.resblocks.5.convs1.2.weight_g\", \"generator.resblocks.5.convs1.2.weight_v\", \"generator.resblocks.5.convs2.0.bias\", \"generator.resblocks.5.convs2.0.weight_g\", \"generator.resblocks.5.convs2.0.weight_v\", \"generator.resblocks.5.convs2.1.bias\", \"generator.resblocks.5.convs2.1.weight_g\", \"generator.resblocks.5.convs2.1.weight_v\", \"generator.resblocks.5.convs2.2.bias\", \"generator.resblocks.5.convs2.2.weight_g\", \"generator.resblocks.5.convs2.2.weight_v\", \"generator.resblocks.5.adain1.0.fc.weight\", \"generator.resblocks.5.adain1.0.fc.bias\", \"generator.resblocks.5.adain1.1.fc.weight\", \"generator.resblocks.5.adain1.1.fc.bias\", \"generator.resblocks.5.adain1.2.fc.weight\", \"generator.resblocks.5.adain1.2.fc.bias\", \"generator.resblocks.5.adain2.0.fc.weight\", \"generator.resblocks.5.adain2.0.fc.bias\", \"generator.resblocks.5.adain2.1.fc.weight\", \"generator.resblocks.5.adain2.1.fc.bias\", \"generator.resblocks.5.adain2.2.fc.weight\", \"generator.resblocks.5.adain2.2.fc.bias\", \"generator.resblocks.5.alpha1.0\", \"generator.resblocks.5.alpha1.1\", \"generator.resblocks.5.alpha1.2\", \"generator.resblocks.5.alpha2.0\", \"generator.resblocks.5.alpha2.1\", \"generator.resblocks.5.alpha2.2\", \"generator.resblocks.6.convs1.0.bias\", \"generator.resblocks.6.convs1.0.weight_g\", \"generator.resblocks.6.convs1.0.weight_v\", \"generator.resblocks.6.convs1.1.bias\", \"generator.resblocks.6.convs1.1.weight_g\", \"generator.resblocks.6.convs1.1.weight_v\", \"generator.resblocks.6.convs1.2.bias\", \"generator.resblocks.6.convs1.2.weight_g\", \"generator.resblocks.6.convs1.2.weight_v\", \"generator.resblocks.6.convs2.0.bias\", \"generator.resblocks.6.convs2.0.weight_g\", \"generator.resblocks.6.convs2.0.weight_v\", \"generator.resblocks.6.convs2.1.bias\", \"generator.resblocks.6.convs2.1.weight_g\", \"generator.resblocks.6.convs2.1.weight_v\", \"generator.resblocks.6.convs2.2.bias\", \"generator.resblocks.6.convs2.2.weight_g\", \"generator.resblocks.6.convs2.2.weight_v\", \"generator.resblocks.6.adain1.0.fc.weight\", \"generator.resblocks.6.adain1.0.fc.bias\", \"generator.resblocks.6.adain1.1.fc.weight\", \"generator.resblocks.6.adain1.1.fc.bias\", \"generator.resblocks.6.adain1.2.fc.weight\", \"generator.resblocks.6.adain1.2.fc.bias\", \"generator.resblocks.6.adain2.0.fc.weight\", \"generator.resblocks.6.adain2.0.fc.bias\", \"generator.resblocks.6.adain2.1.fc.weight\", \"generator.resblocks.6.adain2.1.fc.bias\", \"generator.resblocks.6.adain2.2.fc.weight\", \"generator.resblocks.6.adain2.2.fc.bias\", \"generator.resblocks.6.alpha1.0\", \"generator.resblocks.6.alpha1.1\", \"generator.resblocks.6.alpha1.2\", \"generator.resblocks.6.alpha2.0\", \"generator.resblocks.6.alpha2.1\", \"generator.resblocks.6.alpha2.2\", \"generator.resblocks.7.convs1.0.bias\", \"generator.resblocks.7.convs1.0.weight_g\", \"generator.resblocks.7.convs1.0.weight_v\", \"generator.resblocks.7.convs1.1.bias\", \"generator.resblocks.7.convs1.1.weight_g\", \"generator.resblocks.7.convs1.1.weight_v\", \"generator.resblocks.7.convs1.2.bias\", \"generator.resblocks.7.convs1.2.weight_g\", \"generator.resblocks.7.convs1.2.weight_v\", \"generator.resblocks.7.convs2.0.bias\", \"generator.resblocks.7.convs2.0.weight_g\", \"generator.resblocks.7.convs2.0.weight_v\", \"generator.resblocks.7.convs2.1.bias\", \"generator.resblocks.7.convs2.1.weight_g\", \"generator.resblocks.7.convs2.1.weight_v\", \"generator.resblocks.7.convs2.2.bias\", \"generator.resblocks.7.convs2.2.weight_g\", \"generator.resblocks.7.convs2.2.weight_v\", \"generator.resblocks.7.adain1.0.fc.weight\", \"generator.resblocks.7.adain1.0.fc.bias\", \"generator.resblocks.7.adain1.1.fc.weight\", \"generator.resblocks.7.adain1.1.fc.bias\", \"generator.resblocks.7.adain1.2.fc.weight\", \"generator.resblocks.7.adain1.2.fc.bias\", \"generator.resblocks.7.adain2.0.fc.weight\", \"generator.resblocks.7.adain2.0.fc.bias\", \"generator.resblocks.7.adain2.1.fc.weight\", \"generator.resblocks.7.adain2.1.fc.bias\", \"generator.resblocks.7.adain2.2.fc.weight\", \"generator.resblocks.7.adain2.2.fc.bias\", \"generator.resblocks.7.alpha1.0\", \"generator.resblocks.7.alpha1.1\", \"generator.resblocks.7.alpha1.2\", \"generator.resblocks.7.alpha2.0\", \"generator.resblocks.7.alpha2.1\", \"generator.resblocks.7.alpha2.2\", \"generator.resblocks.8.convs1.0.bias\", \"generator.resblocks.8.convs1.0.weight_g\", \"generator.resblocks.8.convs1.0.weight_v\", \"generator.resblocks.8.convs1.1.bias\", \"generator.resblocks.8.convs1.1.weight_g\", \"generator.resblocks.8.convs1.1.weight_v\", \"generator.resblocks.8.convs1.2.bias\", \"generator.resblocks.8.convs1.2.weight_g\", \"generator.resblocks.8.convs1.2.weight_v\", \"generator.resblocks.8.convs2.0.bias\", \"generator.resblocks.8.convs2.0.weight_g\", \"generator.resblocks.8.convs2.0.weight_v\", \"generator.resblocks.8.convs2.1.bias\", \"generator.resblocks.8.convs2.1.weight_g\", \"generator.resblocks.8.convs2.1.weight_v\", \"generator.resblocks.8.convs2.2.bias\", \"generator.resblocks.8.convs2.2.weight_g\", \"generator.resblocks.8.convs2.2.weight_v\", \"generator.resblocks.8.adain1.0.fc.weight\", \"generator.resblocks.8.adain1.0.fc.bias\", \"generator.resblocks.8.adain1.1.fc.weight\", \"generator.resblocks.8.adain1.1.fc.bias\", \"generator.resblocks.8.adain1.2.fc.weight\", \"generator.resblocks.8.adain1.2.fc.bias\", \"generator.resblocks.8.adain2.0.fc.weight\", \"generator.resblocks.8.adain2.0.fc.bias\", \"generator.resblocks.8.adain2.1.fc.weight\", \"generator.resblocks.8.adain2.1.fc.bias\", \"generator.resblocks.8.adain2.2.fc.weight\", \"generator.resblocks.8.adain2.2.fc.bias\", \"generator.resblocks.8.alpha1.0\", \"generator.resblocks.8.alpha1.1\", \"generator.resblocks.8.alpha1.2\", \"generator.resblocks.8.alpha2.0\", \"generator.resblocks.8.alpha2.1\", \"generator.resblocks.8.alpha2.2\", \"generator.resblocks.9.convs1.0.bias\", \"generator.resblocks.9.convs1.0.weight_g\", \"generator.resblocks.9.convs1.0.weight_v\", \"generator.resblocks.9.convs1.1.bias\", \"generator.resblocks.9.convs1.1.weight_g\", \"generator.resblocks.9.convs1.1.weight_v\", \"generator.resblocks.9.convs1.2.bias\", \"generator.resblocks.9.convs1.2.weight_g\", \"generator.resblocks.9.convs1.2.weight_v\", \"generator.resblocks.9.convs2.0.bias\", \"generator.resblocks.9.convs2.0.weight_g\", \"generator.resblocks.9.convs2.0.weight_v\", \"generator.resblocks.9.convs2.1.bias\", \"generator.resblocks.9.convs2.1.weight_g\", \"generator.resblocks.9.convs2.1.weight_v\", \"generator.resblocks.9.convs2.2.bias\", \"generator.resblocks.9.convs2.2.weight_g\", \"generator.resblocks.9.convs2.2.weight_v\", \"generator.resblocks.9.adain1.0.fc.weight\", \"generator.resblocks.9.adain1.0.fc.bias\", \"generator.resblocks.9.adain1.1.fc.weight\", \"generator.resblocks.9.adain1.1.fc.bias\", \"generator.resblocks.9.adain1.2.fc.weight\", \"generator.resblocks.9.adain1.2.fc.bias\", \"generator.resblocks.9.adain2.0.fc.weight\", \"generator.resblocks.9.adain2.0.fc.bias\", \"generator.resblocks.9.adain2.1.fc.weight\", \"generator.resblocks.9.adain2.1.fc.bias\", \"generator.resblocks.9.adain2.2.fc.weight\", \"generator.resblocks.9.adain2.2.fc.bias\", \"generator.resblocks.9.alpha1.0\", \"generator.resblocks.9.alpha1.1\", \"generator.resblocks.9.alpha1.2\", \"generator.resblocks.9.alpha2.0\", \"generator.resblocks.9.alpha2.1\", \"generator.resblocks.9.alpha2.2\", \"generator.resblocks.10.convs1.0.bias\", \"generator.resblocks.10.convs1.0.weight_g\", \"generator.resblocks.10.convs1.0.weight_v\", \"generator.resblocks.10.convs1.1.bias\", \"generator.resblocks.10.convs1.1.weight_g\", \"generator.resblocks.10.convs1.1.weight_v\", \"generator.resblocks.10.convs1.2.bias\", \"generator.resblocks.10.convs1.2.weight_g\", \"generator.resblocks.10.convs1.2.weight_v\", \"generator.resblocks.10.convs2.0.bias\", \"generator.resblocks.10.convs2.0.weight_g\", \"generator.resblocks.10.convs2.0.weight_v\", \"generator.resblocks.10.convs2.1.bias\", \"generator.resblocks.10.convs2.1.weight_g\", \"generator.resblocks.10.convs2.1.weight_v\", \"generator.resblocks.10.convs2.2.bias\", \"generator.resblocks.10.convs2.2.weight_g\", \"generator.resblocks.10.convs2.2.weight_v\", \"generator.resblocks.10.adain1.0.fc.weight\", \"generator.resblocks.10.adain1.0.fc.bias\", \"generator.resblocks.10.adain1.1.fc.weight\", \"generator.resblocks.10.adain1.1.fc.bias\", \"generator.resblocks.10.adain1.2.fc.weight\", \"generator.resblocks.10.adain1.2.fc.bias\", \"generator.resblocks.10.adain2.0.fc.weight\", \"generator.resblocks.10.adain2.0.fc.bias\", \"generator.resblocks.10.adain2.1.fc.weight\", \"generator.resblocks.10.adain2.1.fc.bias\", \"generator.resblocks.10.adain2.2.fc.weight\", \"generator.resblocks.10.adain2.2.fc.bias\", \"generator.resblocks.10.alpha1.0\", \"generator.resblocks.10.alpha1.1\", \"generator.resblocks.10.alpha1.2\", \"generator.resblocks.10.alpha2.0\", \"generator.resblocks.10.alpha2.1\", \"generator.resblocks.10.alpha2.2\", \"generator.resblocks.11.convs1.0.bias\", \"generator.resblocks.11.convs1.0.weight_g\", \"generator.resblocks.11.convs1.0.weight_v\", \"generator.resblocks.11.convs1.1.bias\", \"generator.resblocks.11.convs1.1.weight_g\", \"generator.resblocks.11.convs1.1.weight_v\", \"generator.resblocks.11.convs1.2.bias\", \"generator.resblocks.11.convs1.2.weight_g\", \"generator.resblocks.11.convs1.2.weight_v\", \"generator.resblocks.11.convs2.0.bias\", \"generator.resblocks.11.convs2.0.weight_g\", \"generator.resblocks.11.convs2.0.weight_v\", \"generator.resblocks.11.convs2.1.bias\", \"generator.resblocks.11.convs2.1.weight_g\", \"generator.resblocks.11.convs2.1.weight_v\", \"generator.resblocks.11.convs2.2.bias\", \"generator.resblocks.11.convs2.2.weight_g\", \"generator.resblocks.11.convs2.2.weight_v\", \"generator.resblocks.11.adain1.0.fc.weight\", \"generator.resblocks.11.adain1.0.fc.bias\", \"generator.resblocks.11.adain1.1.fc.weight\", \"generator.resblocks.11.adain1.1.fc.bias\", \"generator.resblocks.11.adain1.2.fc.weight\", \"generator.resblocks.11.adain1.2.fc.bias\", \"generator.resblocks.11.adain2.0.fc.weight\", \"generator.resblocks.11.adain2.0.fc.bias\", \"generator.resblocks.11.adain2.1.fc.weight\", \"generator.resblocks.11.adain2.1.fc.bias\", \"generator.resblocks.11.adain2.2.fc.weight\", \"generator.resblocks.11.adain2.2.fc.bias\", \"generator.resblocks.11.alpha1.0\", \"generator.resblocks.11.alpha1.1\", \"generator.resblocks.11.alpha1.2\", \"generator.resblocks.11.alpha2.0\", \"generator.resblocks.11.alpha2.1\", \"generator.resblocks.11.alpha2.2\", \"generator.alphas.0\", \"generator.alphas.1\", \"generator.alphas.2\", \"generator.alphas.3\", \"generator.alphas.4\", \"generator.conv_post.bias\", \"generator.conv_post.weight_g\", \"generator.conv_post.weight_v\". \n\tUnexpected key(s) in state_dict: \"to_out.0.bias\", \"to_out.0.weight_g\", \"to_out.0.weight_v\", \"decode.4.conv1.bias\", \"decode.4.conv1.weight_g\", \"decode.4.conv1.weight_v\", \"decode.4.conv2.bias\", \"decode.4.conv2.weight_g\", \"decode.4.conv2.weight_v\", \"decode.4.norm1.fc.weight\", \"decode.4.norm1.fc.bias\", \"decode.4.norm2.fc.weight\", \"decode.4.norm2.fc.bias\", \"decode.2.pool.bias\", \"decode.2.pool.weight_g\", \"decode.2.pool.weight_v\", \"encode.0.conv1.bias\", \"encode.0.conv1.weight_g\", \"encode.0.conv1.weight_v\", \"encode.0.conv2.bias\", \"encode.0.conv2.weight_g\", \"encode.0.conv2.weight_v\", \"encode.0.norm1.weight\", \"encode.0.norm1.bias\", \"encode.0.norm2.weight\", \"encode.0.norm2.bias\", \"encode.0.conv1x1.weight_g\", \"encode.0.conv1x1.weight_v\", \"encode.1.conv1.bias\", \"encode.1.conv1.weight_g\", \"encode.1.conv1.weight_v\", \"encode.1.conv2.bias\", \"encode.1.conv2.weight_g\", \"encode.1.conv2.weight_v\", \"encode.1.norm1.weight\", \"encode.1.norm1.bias\", \"encode.1.norm2.weight\", \"encode.1.norm2.bias\", \"F0_conv.0.conv1.bias\", \"F0_conv.0.conv1.weight_g\", \"F0_conv.0.conv1.weight_v\", \"F0_conv.0.conv2.bias\", \"F0_conv.0.conv2.weight_g\", \"F0_conv.0.conv2.weight_v\", \"F0_conv.0.norm1.weight\", \"F0_conv.0.norm1.bias\", \"F0_conv.0.norm2.weight\", \"F0_conv.0.norm2.bias\", \"F0_conv.0.conv1x1.weight_g\", \"F0_conv.0.conv1x1.weight_v\", \"F0_conv.0.pool.bias\", \"F0_conv.0.pool.weight_g\", \"F0_conv.0.pool.weight_v\", \"F0_conv.1.bias\", \"F0_conv.1.weight_g\", \"F0_conv.1.weight_v\", \"F0_conv.2.weight\", \"F0_conv.2.bias\", \"N_conv.0.conv1.bias\", \"N_conv.0.conv1.weight_g\", \"N_conv.0.conv1.weight_v\", \"N_conv.0.conv2.bias\", \"N_conv.0.conv2.weight_g\", \"N_conv.0.conv2.weight_v\", \"N_conv.0.norm1.weight\", \"N_conv.0.norm1.bias\", \"N_conv.0.norm2.weight\", \"N_conv.0.norm2.bias\", \"N_conv.0.conv1x1.weight_g\", \"N_conv.0.conv1x1.weight_v\", \"N_conv.0.pool.bias\", \"N_conv.0.pool.weight_g\", \"N_conv.0.pool.weight_v\", \"N_conv.1.bias\", \"N_conv.1.weight_g\", \"N_conv.1.weight_v\", \"N_conv.2.weight\", \"N_conv.2.bias\", \"asr_res.1.weight\", \"asr_res.1.bias\". \n\tsize mismatch for decode.2.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decode.2.conv1.weight_g: copying a param with shape torch.Size([512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1, 1]).\n\tsize mismatch for decode.2.conv1.weight_v: copying a param with shape torch.Size([512, 1090, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1090, 3]).\n\tsize mismatch for decode.2.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decode.2.conv2.weight_g: copying a param with shape torch.Size([512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1, 1]).\n\tsize mismatch for decode.2.conv2.weight_v: copying a param with shape torch.Size([512, 512, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3]).\n\tsize mismatch for decode.2.norm2.fc.weight: copying a param with shape torch.Size([1024, 128]) from checkpoint, the shape in current model is torch.Size([2048, 128]).\n\tsize mismatch for decode.2.norm2.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for decode.2.conv1x1.weight_g: copying a param with shape torch.Size([512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1, 1]).\n\tsize mismatch for decode.2.conv1x1.weight_v: copying a param with shape torch.Size([512, 1090, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1090, 1]).\n\tsize mismatch for decode.3.conv1.weight_v: copying a param with shape torch.Size([512, 512, 3]) from checkpoint, the shape in current model is torch.Size([512, 1090, 3]).\n\tsize mismatch for decode.3.norm1.fc.weight: copying a param with shape torch.Size([1024, 128]) from checkpoint, the shape in current model is torch.Size([2180, 128]).\n\tsize mismatch for decode.3.norm1.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2180]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 84\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiscriminator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key:\n\u001b[0;32m     83\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m loaded\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m key)\n\u001b[1;32m---> 84\u001b[0m             \u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Set model to evaluation mode\u001b[39;00m\n\u001b[0;32m     87\u001b[0m _ \u001b[38;5;241m=\u001b[39m [model[key]\u001b[38;5;241m.\u001b[39meval() \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m model]\n",
      "File \u001b[1;32mc:\\Users\\garym\\OneDrive\\Scripts\\GM_Alienware\\opt\\Conda\\envs\\styletts\\lib\\site-packages\\torch\\nn\\modules\\module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[0;32m   2580\u001b[0m             ),\n\u001b[0;32m   2581\u001b[0m         )\n\u001b[0;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[0;32m   2587\u001b[0m         )\n\u001b[0;32m   2588\u001b[0m     )\n\u001b[0;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Decoder:\n\tMissing key(s) in state_dict: \"decode.3.conv1x1.weight_g\", \"decode.3.conv1x1.weight_v\", \"decode.3.pool.bias\", \"decode.3.pool.weight_g\", \"decode.3.pool.weight_v\", \"encode.conv1.bias\", \"encode.conv1.weight_g\", \"encode.conv1.weight_v\", \"encode.conv2.bias\", \"encode.conv2.weight_g\", \"encode.conv2.weight_v\", \"encode.norm1.fc.weight\", \"encode.norm1.fc.bias\", \"encode.norm2.fc.weight\", \"encode.norm2.fc.bias\", \"encode.conv1x1.weight_g\", \"encode.conv1x1.weight_v\", \"F0_conv.bias\", \"F0_conv.weight_g\", \"F0_conv.weight_v\", \"N_conv.bias\", \"N_conv.weight_g\", \"N_conv.weight_v\", \"generator.m_source.l_linear.weight\", \"generator.m_source.l_linear.bias\", \"generator.noise_convs.0.weight\", \"generator.noise_convs.0.bias\", \"generator.noise_convs.1.weight\", \"generator.noise_convs.1.bias\", \"generator.noise_convs.2.weight\", \"generator.noise_convs.2.bias\", \"generator.noise_convs.3.weight\", \"generator.noise_convs.3.bias\", \"generator.ups.0.bias\", \"generator.ups.0.weight_g\", \"generator.ups.0.weight_v\", \"generator.ups.1.bias\", \"generator.ups.1.weight_g\", \"generator.ups.1.weight_v\", \"generator.ups.2.bias\", \"generator.ups.2.weight_g\", \"generator.ups.2.weight_v\", \"generator.ups.3.bias\", \"generator.ups.3.weight_g\", \"generator.ups.3.weight_v\", \"generator.noise_res.0.convs1.0.bias\", \"generator.noise_res.0.convs1.0.weight_g\", \"generator.noise_res.0.convs1.0.weight_v\", \"generator.noise_res.0.convs1.1.bias\", \"generator.noise_res.0.convs1.1.weight_g\", \"generator.noise_res.0.convs1.1.weight_v\", \"generator.noise_res.0.convs1.2.bias\", \"generator.noise_res.0.convs1.2.weight_g\", \"generator.noise_res.0.convs1.2.weight_v\", \"generator.noise_res.0.convs2.0.bias\", \"generator.noise_res.0.convs2.0.weight_g\", \"generator.noise_res.0.convs2.0.weight_v\", \"generator.noise_res.0.convs2.1.bias\", \"generator.noise_res.0.convs2.1.weight_g\", \"generator.noise_res.0.convs2.1.weight_v\", \"generator.noise_res.0.convs2.2.bias\", \"generator.noise_res.0.convs2.2.weight_g\", \"generator.noise_res.0.convs2.2.weight_v\", \"generator.noise_res.0.adain1.0.fc.weight\", \"generator.noise_res.0.adain1.0.fc.bias\", \"generator.noise_res.0.adain1.1.fc.weight\", \"generator.noise_res.0.adain1.1.fc.bias\", \"generator.noise_res.0.adain1.2.fc.weight\", \"generator.noise_res.0.adain1.2.fc.bias\", \"generator.noise_res.0.adain2.0.fc.weight\", \"generator.noise_res.0.adain2.0.fc.bias\", \"generator.noise_res.0.adain2.1.fc.weight\", \"generator.noise_res.0.adain2.1.fc.bias\", \"generator.noise_res.0.adain2.2.fc.weight\", \"generator.noise_res.0.adain2.2.fc.bias\", \"generator.noise_res.0.alpha1.0\", \"generator.noise_res.0.alpha1.1\", \"generator.noise_res.0.alpha1.2\", \"generator.noise_res.0.alpha2.0\", \"generator.noise_res.0.alpha2.1\", \"generator.noise_res.0.alpha2.2\", \"generator.noise_res.1.convs1.0.bias\", \"generator.noise_res.1.convs1.0.weight_g\", \"generator.noise_res.1.convs1.0.weight_v\", \"generator.noise_res.1.convs1.1.bias\", \"generator.noise_res.1.convs1.1.weight_g\", \"generator.noise_res.1.convs1.1.weight_v\", \"generator.noise_res.1.convs1.2.bias\", \"generator.noise_res.1.convs1.2.weight_g\", \"generator.noise_res.1.convs1.2.weight_v\", \"generator.noise_res.1.convs2.0.bias\", \"generator.noise_res.1.convs2.0.weight_g\", \"generator.noise_res.1.convs2.0.weight_v\", \"generator.noise_res.1.convs2.1.bias\", \"generator.noise_res.1.convs2.1.weight_g\", \"generator.noise_res.1.convs2.1.weight_v\", \"generator.noise_res.1.convs2.2.bias\", \"generator.noise_res.1.convs2.2.weight_g\", \"generator.noise_res.1.convs2.2.weight_v\", \"generator.noise_res.1.adain1.0.fc.weight\", \"generator.noise_res.1.adain1.0.fc.bias\", \"generator.noise_res.1.adain1.1.fc.weight\", \"generator.noise_res.1.adain1.1.fc.bias\", \"generator.noise_res.1.adain1.2.fc.weight\", \"generator.noise_res.1.adain1.2.fc.bias\", \"generator.noise_res.1.adain2.0.fc.weight\", \"generator.noise_res.1.adain2.0.fc.bias\", \"generator.noise_res.1.adain2.1.fc.weight\", \"generator.noise_res.1.adain2.1.fc.bias\", \"generator.noise_res.1.adain2.2.fc.weight\", \"generator.noise_res.1.adain2.2.fc.bias\", \"generator.noise_res.1.alpha1.0\", \"generator.noise_res.1.alpha1.1\", \"generator.noise_res.1.alpha1.2\", \"generator.noise_res.1.alpha2.0\", \"generator.noise_res.1.alpha2.1\", \"generator.noise_res.1.alpha2.2\", \"generator.noise_res.2.convs1.0.bias\", \"generator.noise_res.2.convs1.0.weight_g\", \"generator.noise_res.2.convs1.0.weight_v\", \"generator.noise_res.2.convs1.1.bias\", \"generator.noise_res.2.convs1.1.weight_g\", \"generator.noise_res.2.convs1.1.weight_v\", \"generator.noise_res.2.convs1.2.bias\", \"generator.noise_res.2.convs1.2.weight_g\", \"generator.noise_res.2.convs1.2.weight_v\", \"generator.noise_res.2.convs2.0.bias\", \"generator.noise_res.2.convs2.0.weight_g\", \"generator.noise_res.2.convs2.0.weight_v\", \"generator.noise_res.2.convs2.1.bias\", \"generator.noise_res.2.convs2.1.weight_g\", \"generator.noise_res.2.convs2.1.weight_v\", \"generator.noise_res.2.convs2.2.bias\", \"generator.noise_res.2.convs2.2.weight_g\", \"generator.noise_res.2.convs2.2.weight_v\", \"generator.noise_res.2.adain1.0.fc.weight\", \"generator.noise_res.2.adain1.0.fc.bias\", \"generator.noise_res.2.adain1.1.fc.weight\", \"generator.noise_res.2.adain1.1.fc.bias\", \"generator.noise_res.2.adain1.2.fc.weight\", \"generator.noise_res.2.adain1.2.fc.bias\", \"generator.noise_res.2.adain2.0.fc.weight\", \"generator.noise_res.2.adain2.0.fc.bias\", \"generator.noise_res.2.adain2.1.fc.weight\", \"generator.noise_res.2.adain2.1.fc.bias\", \"generator.noise_res.2.adain2.2.fc.weight\", \"generator.noise_res.2.adain2.2.fc.bias\", \"generator.noise_res.2.alpha1.0\", \"generator.noise_res.2.alpha1.1\", \"generator.noise_res.2.alpha1.2\", \"generator.noise_res.2.alpha2.0\", \"generator.noise_res.2.alpha2.1\", \"generator.noise_res.2.alpha2.2\", \"generator.noise_res.3.convs1.0.bias\", \"generator.noise_res.3.convs1.0.weight_g\", \"generator.noise_res.3.convs1.0.weight_v\", \"generator.noise_res.3.convs1.1.bias\", \"generator.noise_res.3.convs1.1.weight_g\", \"generator.noise_res.3.convs1.1.weight_v\", \"generator.noise_res.3.convs1.2.bias\", \"generator.noise_res.3.convs1.2.weight_g\", \"generator.noise_res.3.convs1.2.weight_v\", \"generator.noise_res.3.convs2.0.bias\", \"generator.noise_res.3.convs2.0.weight_g\", \"generator.noise_res.3.convs2.0.weight_v\", \"generator.noise_res.3.convs2.1.bias\", \"generator.noise_res.3.convs2.1.weight_g\", \"generator.noise_res.3.convs2.1.weight_v\", \"generator.noise_res.3.convs2.2.bias\", \"generator.noise_res.3.convs2.2.weight_g\", \"generator.noise_res.3.convs2.2.weight_v\", \"generator.noise_res.3.adain1.0.fc.weight\", \"generator.noise_res.3.adain1.0.fc.bias\", \"generator.noise_res.3.adain1.1.fc.weight\", \"generator.noise_res.3.adain1.1.fc.bias\", \"generator.noise_res.3.adain1.2.fc.weight\", \"generator.noise_res.3.adain1.2.fc.bias\", \"generator.noise_res.3.adain2.0.fc.weight\", \"generator.noise_res.3.adain2.0.fc.bias\", \"generator.noise_res.3.adain2.1.fc.weight\", \"generator.noise_res.3.adain2.1.fc.bias\", \"generator.noise_res.3.adain2.2.fc.weight\", \"generator.noise_res.3.adain2.2.fc.bias\", \"generator.noise_res.3.alpha1.0\", \"generator.noise_res.3.alpha1.1\", \"generator.noise_res.3.alpha1.2\", \"generator.noise_res.3.alpha2.0\", \"generator.noise_res.3.alpha2.1\", \"generator.noise_res.3.alpha2.2\", \"generator.resblocks.0.convs1.0.bias\", \"generator.resblocks.0.convs1.0.weight_g\", \"generator.resblocks.0.convs1.0.weight_v\", \"generator.resblocks.0.convs1.1.bias\", \"generator.resblocks.0.convs1.1.weight_g\", \"generator.resblocks.0.convs1.1.weight_v\", \"generator.resblocks.0.convs1.2.bias\", \"generator.resblocks.0.convs1.2.weight_g\", \"generator.resblocks.0.convs1.2.weight_v\", \"generator.resblocks.0.convs2.0.bias\", \"generator.resblocks.0.convs2.0.weight_g\", \"generator.resblocks.0.convs2.0.weight_v\", \"generator.resblocks.0.convs2.1.bias\", \"generator.resblocks.0.convs2.1.weight_g\", \"generator.resblocks.0.convs2.1.weight_v\", \"generator.resblocks.0.convs2.2.bias\", \"generator.resblocks.0.convs2.2.weight_g\", \"generator.resblocks.0.convs2.2.weight_v\", \"generator.resblocks.0.adain1.0.fc.weight\", \"generator.resblocks.0.adain1.0.fc.bias\", \"generator.resblocks.0.adain1.1.fc.weight\", \"generator.resblocks.0.adain1.1.fc.bias\", \"generator.resblocks.0.adain1.2.fc.weight\", \"generator.resblocks.0.adain1.2.fc.bias\", \"generator.resblocks.0.adain2.0.fc.weight\", \"generator.resblocks.0.adain2.0.fc.bias\", \"generator.resblocks.0.adain2.1.fc.weight\", \"generator.resblocks.0.adain2.1.fc.bias\", \"generator.resblocks.0.adain2.2.fc.weight\", \"generator.resblocks.0.adain2.2.fc.bias\", \"generator.resblocks.0.alpha1.0\", \"generator.resblocks.0.alpha1.1\", \"generator.resblocks.0.alpha1.2\", \"generator.resblocks.0.alpha2.0\", \"generator.resblocks.0.alpha2.1\", \"generator.resblocks.0.alpha2.2\", \"generator.resblocks.1.convs1.0.bias\", \"generator.resblocks.1.convs1.0.weight_g\", \"generator.resblocks.1.convs1.0.weight_v\", \"generator.resblocks.1.convs1.1.bias\", \"generator.resblocks.1.convs1.1.weight_g\", \"generator.resblocks.1.convs1.1.weight_v\", \"generator.resblocks.1.convs1.2.bias\", \"generator.resblocks.1.convs1.2.weight_g\", \"generator.resblocks.1.convs1.2.weight_v\", \"generator.resblocks.1.convs2.0.bias\", \"generator.resblocks.1.convs2.0.weight_g\", \"generator.resblocks.1.convs2.0.weight_v\", \"generator.resblocks.1.convs2.1.bias\", \"generator.resblocks.1.convs2.1.weight_g\", \"generator.resblocks.1.convs2.1.weight_v\", \"generator.resblocks.1.convs2.2.bias\", \"generator.resblocks.1.convs2.2.weight_g\", \"generator.resblocks.1.convs2.2.weight_v\", \"generator.resblocks.1.adain1.0.fc.weight\", \"generator.resblocks.1.adain1.0.fc.bias\", \"generator.resblocks.1.adain1.1.fc.weight\", \"generator.resblocks.1.adain1.1.fc.bias\", \"generator.resblocks.1.adain1.2.fc.weight\", \"generator.resblocks.1.adain1.2.fc.bias\", \"generator.resblocks.1.adain2.0.fc.weight\", \"generator.resblocks.1.adain2.0.fc.bias\", \"generator.resblocks.1.adain2.1.fc.weight\", \"generator.resblocks.1.adain2.1.fc.bias\", \"generator.resblocks.1.adain2.2.fc.weight\", \"generator.resblocks.1.adain2.2.fc.bias\", \"generator.resblocks.1.alpha1.0\", \"generator.resblocks.1.alpha1.1\", \"generator.resblocks.1.alpha1.2\", \"generator.resblocks.1.alpha2.0\", \"generator.resblocks.1.alpha2.1\", \"generator.resblocks.1.alpha2.2\", \"generator.resblocks.2.convs1.0.bias\", \"generator.resblocks.2.convs1.0.weight_g\", \"generator.resblocks.2.convs1.0.weight_v\", \"generator.resblocks.2.convs1.1.bias\", \"generator.resblocks.2.convs1.1.weight_g\", \"generator.resblocks.2.convs1.1.weight_v\", \"generator.resblocks.2.convs1.2.bias\", \"generator.resblocks.2.convs1.2.weight_g\", \"generator.resblocks.2.convs1.2.weight_v\", \"generator.resblocks.2.convs2.0.bias\", \"generator.resblocks.2.convs2.0.weight_g\", \"generator.resblocks.2.convs2.0.weight_v\", \"generator.resblocks.2.convs2.1.bias\", \"generator.resblocks.2.convs2.1.weight_g\", \"generator.resblocks.2.convs2.1.weight_v\", \"generator.resblocks.2.convs2.2.bias\", \"generator.resblocks.2.convs2.2.weight_g\", \"generator.resblocks.2.convs2.2.weight_v\", \"generator.resblocks.2.adain1.0.fc.weight\", \"generator.resblocks.2.adain1.0.fc.bias\", \"generator.resblocks.2.adain1.1.fc.weight\", \"generator.resblocks.2.adain1.1.fc.bias\", \"generator.resblocks.2.adain1.2.fc.weight\", \"generator.resblocks.2.adain1.2.fc.bias\", \"generator.resblocks.2.adain2.0.fc.weight\", \"generator.resblocks.2.adain2.0.fc.bias\", \"generator.resblocks.2.adain2.1.fc.weight\", \"generator.resblocks.2.adain2.1.fc.bias\", \"generator.resblocks.2.adain2.2.fc.weight\", \"generator.resblocks.2.adain2.2.fc.bias\", \"generator.resblocks.2.alpha1.0\", \"generator.resblocks.2.alpha1.1\", \"generator.resblocks.2.alpha1.2\", \"generator.resblocks.2.alpha2.0\", \"generator.resblocks.2.alpha2.1\", \"generator.resblocks.2.alpha2.2\", \"generator.resblocks.3.convs1.0.bias\", \"generator.resblocks.3.convs1.0.weight_g\", \"generator.resblocks.3.convs1.0.weight_v\", \"generator.resblocks.3.convs1.1.bias\", \"generator.resblocks.3.convs1.1.weight_g\", \"generator.resblocks.3.convs1.1.weight_v\", \"generator.resblocks.3.convs1.2.bias\", \"generator.resblocks.3.convs1.2.weight_g\", \"generator.resblocks.3.convs1.2.weight_v\", \"generator.resblocks.3.convs2.0.bias\", \"generator.resblocks.3.convs2.0.weight_g\", \"generator.resblocks.3.convs2.0.weight_v\", \"generator.resblocks.3.convs2.1.bias\", \"generator.resblocks.3.convs2.1.weight_g\", \"generator.resblocks.3.convs2.1.weight_v\", \"generator.resblocks.3.convs2.2.bias\", \"generator.resblocks.3.convs2.2.weight_g\", \"generator.resblocks.3.convs2.2.weight_v\", \"generator.resblocks.3.adain1.0.fc.weight\", \"generator.resblocks.3.adain1.0.fc.bias\", \"generator.resblocks.3.adain1.1.fc.weight\", \"generator.resblocks.3.adain1.1.fc.bias\", \"generator.resblocks.3.adain1.2.fc.weight\", \"generator.resblocks.3.adain1.2.fc.bias\", \"generator.resblocks.3.adain2.0.fc.weight\", \"generator.resblocks.3.adain2.0.fc.bias\", \"generator.resblocks.3.adain2.1.fc.weight\", \"generator.resblocks.3.adain2.1.fc.bias\", \"generator.resblocks.3.adain2.2.fc.weight\", \"generator.resblocks.3.adain2.2.fc.bias\", \"generator.resblocks.3.alpha1.0\", \"generator.resblocks.3.alpha1.1\", \"generator.resblocks.3.alpha1.2\", \"generator.resblocks.3.alpha2.0\", \"generator.resblocks.3.alpha2.1\", \"generator.resblocks.3.alpha2.2\", \"generator.resblocks.4.convs1.0.bias\", \"generator.resblocks.4.convs1.0.weight_g\", \"generator.resblocks.4.convs1.0.weight_v\", \"generator.resblocks.4.convs1.1.bias\", \"generator.resblocks.4.convs1.1.weight_g\", \"generator.resblocks.4.convs1.1.weight_v\", \"generator.resblocks.4.convs1.2.bias\", \"generator.resblocks.4.convs1.2.weight_g\", \"generator.resblocks.4.convs1.2.weight_v\", \"generator.resblocks.4.convs2.0.bias\", \"generator.resblocks.4.convs2.0.weight_g\", \"generator.resblocks.4.convs2.0.weight_v\", \"generator.resblocks.4.convs2.1.bias\", \"generator.resblocks.4.convs2.1.weight_g\", \"generator.resblocks.4.convs2.1.weight_v\", \"generator.resblocks.4.convs2.2.bias\", \"generator.resblocks.4.convs2.2.weight_g\", \"generator.resblocks.4.convs2.2.weight_v\", \"generator.resblocks.4.adain1.0.fc.weight\", \"generator.resblocks.4.adain1.0.fc.bias\", \"generator.resblocks.4.adain1.1.fc.weight\", \"generator.resblocks.4.adain1.1.fc.bias\", \"generator.resblocks.4.adain1.2.fc.weight\", \"generator.resblocks.4.adain1.2.fc.bias\", \"generator.resblocks.4.adain2.0.fc.weight\", \"generator.resblocks.4.adain2.0.fc.bias\", \"generator.resblocks.4.adain2.1.fc.weight\", \"generator.resblocks.4.adain2.1.fc.bias\", \"generator.resblocks.4.adain2.2.fc.weight\", \"generator.resblocks.4.adain2.2.fc.bias\", \"generator.resblocks.4.alpha1.0\", \"generator.resblocks.4.alpha1.1\", \"generator.resblocks.4.alpha1.2\", \"generator.resblocks.4.alpha2.0\", \"generator.resblocks.4.alpha2.1\", \"generator.resblocks.4.alpha2.2\", \"generator.resblocks.5.convs1.0.bias\", \"generator.resblocks.5.convs1.0.weight_g\", \"generator.resblocks.5.convs1.0.weight_v\", \"generator.resblocks.5.convs1.1.bias\", \"generator.resblocks.5.convs1.1.weight_g\", \"generator.resblocks.5.convs1.1.weight_v\", \"generator.resblocks.5.convs1.2.bias\", \"generator.resblocks.5.convs1.2.weight_g\", \"generator.resblocks.5.convs1.2.weight_v\", \"generator.resblocks.5.convs2.0.bias\", \"generator.resblocks.5.convs2.0.weight_g\", \"generator.resblocks.5.convs2.0.weight_v\", \"generator.resblocks.5.convs2.1.bias\", \"generator.resblocks.5.convs2.1.weight_g\", \"generator.resblocks.5.convs2.1.weight_v\", \"generator.resblocks.5.convs2.2.bias\", \"generator.resblocks.5.convs2.2.weight_g\", \"generator.resblocks.5.convs2.2.weight_v\", \"generator.resblocks.5.adain1.0.fc.weight\", \"generator.resblocks.5.adain1.0.fc.bias\", \"generator.resblocks.5.adain1.1.fc.weight\", \"generator.resblocks.5.adain1.1.fc.bias\", \"generator.resblocks.5.adain1.2.fc.weight\", \"generator.resblocks.5.adain1.2.fc.bias\", \"generator.resblocks.5.adain2.0.fc.weight\", \"generator.resblocks.5.adain2.0.fc.bias\", \"generator.resblocks.5.adain2.1.fc.weight\", \"generator.resblocks.5.adain2.1.fc.bias\", \"generator.resblocks.5.adain2.2.fc.weight\", \"generator.resblocks.5.adain2.2.fc.bias\", \"generator.resblocks.5.alpha1.0\", \"generator.resblocks.5.alpha1.1\", \"generator.resblocks.5.alpha1.2\", \"generator.resblocks.5.alpha2.0\", \"generator.resblocks.5.alpha2.1\", \"generator.resblocks.5.alpha2.2\", \"generator.resblocks.6.convs1.0.bias\", \"generator.resblocks.6.convs1.0.weight_g\", \"generator.resblocks.6.convs1.0.weight_v\", \"generator.resblocks.6.convs1.1.bias\", \"generator.resblocks.6.convs1.1.weight_g\", \"generator.resblocks.6.convs1.1.weight_v\", \"generator.resblocks.6.convs1.2.bias\", \"generator.resblocks.6.convs1.2.weight_g\", \"generator.resblocks.6.convs1.2.weight_v\", \"generator.resblocks.6.convs2.0.bias\", \"generator.resblocks.6.convs2.0.weight_g\", \"generator.resblocks.6.convs2.0.weight_v\", \"generator.resblocks.6.convs2.1.bias\", \"generator.resblocks.6.convs2.1.weight_g\", \"generator.resblocks.6.convs2.1.weight_v\", \"generator.resblocks.6.convs2.2.bias\", \"generator.resblocks.6.convs2.2.weight_g\", \"generator.resblocks.6.convs2.2.weight_v\", \"generator.resblocks.6.adain1.0.fc.weight\", \"generator.resblocks.6.adain1.0.fc.bias\", \"generator.resblocks.6.adain1.1.fc.weight\", \"generator.resblocks.6.adain1.1.fc.bias\", \"generator.resblocks.6.adain1.2.fc.weight\", \"generator.resblocks.6.adain1.2.fc.bias\", \"generator.resblocks.6.adain2.0.fc.weight\", \"generator.resblocks.6.adain2.0.fc.bias\", \"generator.resblocks.6.adain2.1.fc.weight\", \"generator.resblocks.6.adain2.1.fc.bias\", \"generator.resblocks.6.adain2.2.fc.weight\", \"generator.resblocks.6.adain2.2.fc.bias\", \"generator.resblocks.6.alpha1.0\", \"generator.resblocks.6.alpha1.1\", \"generator.resblocks.6.alpha1.2\", \"generator.resblocks.6.alpha2.0\", \"generator.resblocks.6.alpha2.1\", \"generator.resblocks.6.alpha2.2\", \"generator.resblocks.7.convs1.0.bias\", \"generator.resblocks.7.convs1.0.weight_g\", \"generator.resblocks.7.convs1.0.weight_v\", \"generator.resblocks.7.convs1.1.bias\", \"generator.resblocks.7.convs1.1.weight_g\", \"generator.resblocks.7.convs1.1.weight_v\", \"generator.resblocks.7.convs1.2.bias\", \"generator.resblocks.7.convs1.2.weight_g\", \"generator.resblocks.7.convs1.2.weight_v\", \"generator.resblocks.7.convs2.0.bias\", \"generator.resblocks.7.convs2.0.weight_g\", \"generator.resblocks.7.convs2.0.weight_v\", \"generator.resblocks.7.convs2.1.bias\", \"generator.resblocks.7.convs2.1.weight_g\", \"generator.resblocks.7.convs2.1.weight_v\", \"generator.resblocks.7.convs2.2.bias\", \"generator.resblocks.7.convs2.2.weight_g\", \"generator.resblocks.7.convs2.2.weight_v\", \"generator.resblocks.7.adain1.0.fc.weight\", \"generator.resblocks.7.adain1.0.fc.bias\", \"generator.resblocks.7.adain1.1.fc.weight\", \"generator.resblocks.7.adain1.1.fc.bias\", \"generator.resblocks.7.adain1.2.fc.weight\", \"generator.resblocks.7.adain1.2.fc.bias\", \"generator.resblocks.7.adain2.0.fc.weight\", \"generator.resblocks.7.adain2.0.fc.bias\", \"generator.resblocks.7.adain2.1.fc.weight\", \"generator.resblocks.7.adain2.1.fc.bias\", \"generator.resblocks.7.adain2.2.fc.weight\", \"generator.resblocks.7.adain2.2.fc.bias\", \"generator.resblocks.7.alpha1.0\", \"generator.resblocks.7.alpha1.1\", \"generator.resblocks.7.alpha1.2\", \"generator.resblocks.7.alpha2.0\", \"generator.resblocks.7.alpha2.1\", \"generator.resblocks.7.alpha2.2\", \"generator.resblocks.8.convs1.0.bias\", \"generator.resblocks.8.convs1.0.weight_g\", \"generator.resblocks.8.convs1.0.weight_v\", \"generator.resblocks.8.convs1.1.bias\", \"generator.resblocks.8.convs1.1.weight_g\", \"generator.resblocks.8.convs1.1.weight_v\", \"generator.resblocks.8.convs1.2.bias\", \"generator.resblocks.8.convs1.2.weight_g\", \"generator.resblocks.8.convs1.2.weight_v\", \"generator.resblocks.8.convs2.0.bias\", \"generator.resblocks.8.convs2.0.weight_g\", \"generator.resblocks.8.convs2.0.weight_v\", \"generator.resblocks.8.convs2.1.bias\", \"generator.resblocks.8.convs2.1.weight_g\", \"generator.resblocks.8.convs2.1.weight_v\", \"generator.resblocks.8.convs2.2.bias\", \"generator.resblocks.8.convs2.2.weight_g\", \"generator.resblocks.8.convs2.2.weight_v\", \"generator.resblocks.8.adain1.0.fc.weight\", \"generator.resblocks.8.adain1.0.fc.bias\", \"generator.resblocks.8.adain1.1.fc.weight\", \"generator.resblocks.8.adain1.1.fc.bias\", \"generator.resblocks.8.adain1.2.fc.weight\", \"generator.resblocks.8.adain1.2.fc.bias\", \"generator.resblocks.8.adain2.0.fc.weight\", \"generator.resblocks.8.adain2.0.fc.bias\", \"generator.resblocks.8.adain2.1.fc.weight\", \"generator.resblocks.8.adain2.1.fc.bias\", \"generator.resblocks.8.adain2.2.fc.weight\", \"generator.resblocks.8.adain2.2.fc.bias\", \"generator.resblocks.8.alpha1.0\", \"generator.resblocks.8.alpha1.1\", \"generator.resblocks.8.alpha1.2\", \"generator.resblocks.8.alpha2.0\", \"generator.resblocks.8.alpha2.1\", \"generator.resblocks.8.alpha2.2\", \"generator.resblocks.9.convs1.0.bias\", \"generator.resblocks.9.convs1.0.weight_g\", \"generator.resblocks.9.convs1.0.weight_v\", \"generator.resblocks.9.convs1.1.bias\", \"generator.resblocks.9.convs1.1.weight_g\", \"generator.resblocks.9.convs1.1.weight_v\", \"generator.resblocks.9.convs1.2.bias\", \"generator.resblocks.9.convs1.2.weight_g\", \"generator.resblocks.9.convs1.2.weight_v\", \"generator.resblocks.9.convs2.0.bias\", \"generator.resblocks.9.convs2.0.weight_g\", \"generator.resblocks.9.convs2.0.weight_v\", \"generator.resblocks.9.convs2.1.bias\", \"generator.resblocks.9.convs2.1.weight_g\", \"generator.resblocks.9.convs2.1.weight_v\", \"generator.resblocks.9.convs2.2.bias\", \"generator.resblocks.9.convs2.2.weight_g\", \"generator.resblocks.9.convs2.2.weight_v\", \"generator.resblocks.9.adain1.0.fc.weight\", \"generator.resblocks.9.adain1.0.fc.bias\", \"generator.resblocks.9.adain1.1.fc.weight\", \"generator.resblocks.9.adain1.1.fc.bias\", \"generator.resblocks.9.adain1.2.fc.weight\", \"generator.resblocks.9.adain1.2.fc.bias\", \"generator.resblocks.9.adain2.0.fc.weight\", \"generator.resblocks.9.adain2.0.fc.bias\", \"generator.resblocks.9.adain2.1.fc.weight\", \"generator.resblocks.9.adain2.1.fc.bias\", \"generator.resblocks.9.adain2.2.fc.weight\", \"generator.resblocks.9.adain2.2.fc.bias\", \"generator.resblocks.9.alpha1.0\", \"generator.resblocks.9.alpha1.1\", \"generator.resblocks.9.alpha1.2\", \"generator.resblocks.9.alpha2.0\", \"generator.resblocks.9.alpha2.1\", \"generator.resblocks.9.alpha2.2\", \"generator.resblocks.10.convs1.0.bias\", \"generator.resblocks.10.convs1.0.weight_g\", \"generator.resblocks.10.convs1.0.weight_v\", \"generator.resblocks.10.convs1.1.bias\", \"generator.resblocks.10.convs1.1.weight_g\", \"generator.resblocks.10.convs1.1.weight_v\", \"generator.resblocks.10.convs1.2.bias\", \"generator.resblocks.10.convs1.2.weight_g\", \"generator.resblocks.10.convs1.2.weight_v\", \"generator.resblocks.10.convs2.0.bias\", \"generator.resblocks.10.convs2.0.weight_g\", \"generator.resblocks.10.convs2.0.weight_v\", \"generator.resblocks.10.convs2.1.bias\", \"generator.resblocks.10.convs2.1.weight_g\", \"generator.resblocks.10.convs2.1.weight_v\", \"generator.resblocks.10.convs2.2.bias\", \"generator.resblocks.10.convs2.2.weight_g\", \"generator.resblocks.10.convs2.2.weight_v\", \"generator.resblocks.10.adain1.0.fc.weight\", \"generator.resblocks.10.adain1.0.fc.bias\", \"generator.resblocks.10.adain1.1.fc.weight\", \"generator.resblocks.10.adain1.1.fc.bias\", \"generator.resblocks.10.adain1.2.fc.weight\", \"generator.resblocks.10.adain1.2.fc.bias\", \"generator.resblocks.10.adain2.0.fc.weight\", \"generator.resblocks.10.adain2.0.fc.bias\", \"generator.resblocks.10.adain2.1.fc.weight\", \"generator.resblocks.10.adain2.1.fc.bias\", \"generator.resblocks.10.adain2.2.fc.weight\", \"generator.resblocks.10.adain2.2.fc.bias\", \"generator.resblocks.10.alpha1.0\", \"generator.resblocks.10.alpha1.1\", \"generator.resblocks.10.alpha1.2\", \"generator.resblocks.10.alpha2.0\", \"generator.resblocks.10.alpha2.1\", \"generator.resblocks.10.alpha2.2\", \"generator.resblocks.11.convs1.0.bias\", \"generator.resblocks.11.convs1.0.weight_g\", \"generator.resblocks.11.convs1.0.weight_v\", \"generator.resblocks.11.convs1.1.bias\", \"generator.resblocks.11.convs1.1.weight_g\", \"generator.resblocks.11.convs1.1.weight_v\", \"generator.resblocks.11.convs1.2.bias\", \"generator.resblocks.11.convs1.2.weight_g\", \"generator.resblocks.11.convs1.2.weight_v\", \"generator.resblocks.11.convs2.0.bias\", \"generator.resblocks.11.convs2.0.weight_g\", \"generator.resblocks.11.convs2.0.weight_v\", \"generator.resblocks.11.convs2.1.bias\", \"generator.resblocks.11.convs2.1.weight_g\", \"generator.resblocks.11.convs2.1.weight_v\", \"generator.resblocks.11.convs2.2.bias\", \"generator.resblocks.11.convs2.2.weight_g\", \"generator.resblocks.11.convs2.2.weight_v\", \"generator.resblocks.11.adain1.0.fc.weight\", \"generator.resblocks.11.adain1.0.fc.bias\", \"generator.resblocks.11.adain1.1.fc.weight\", \"generator.resblocks.11.adain1.1.fc.bias\", \"generator.resblocks.11.adain1.2.fc.weight\", \"generator.resblocks.11.adain1.2.fc.bias\", \"generator.resblocks.11.adain2.0.fc.weight\", \"generator.resblocks.11.adain2.0.fc.bias\", \"generator.resblocks.11.adain2.1.fc.weight\", \"generator.resblocks.11.adain2.1.fc.bias\", \"generator.resblocks.11.adain2.2.fc.weight\", \"generator.resblocks.11.adain2.2.fc.bias\", \"generator.resblocks.11.alpha1.0\", \"generator.resblocks.11.alpha1.1\", \"generator.resblocks.11.alpha1.2\", \"generator.resblocks.11.alpha2.0\", \"generator.resblocks.11.alpha2.1\", \"generator.resblocks.11.alpha2.2\", \"generator.alphas.0\", \"generator.alphas.1\", \"generator.alphas.2\", \"generator.alphas.3\", \"generator.alphas.4\", \"generator.conv_post.bias\", \"generator.conv_post.weight_g\", \"generator.conv_post.weight_v\". \n\tUnexpected key(s) in state_dict: \"to_out.0.bias\", \"to_out.0.weight_g\", \"to_out.0.weight_v\", \"decode.4.conv1.bias\", \"decode.4.conv1.weight_g\", \"decode.4.conv1.weight_v\", \"decode.4.conv2.bias\", \"decode.4.conv2.weight_g\", \"decode.4.conv2.weight_v\", \"decode.4.norm1.fc.weight\", \"decode.4.norm1.fc.bias\", \"decode.4.norm2.fc.weight\", \"decode.4.norm2.fc.bias\", \"decode.2.pool.bias\", \"decode.2.pool.weight_g\", \"decode.2.pool.weight_v\", \"encode.0.conv1.bias\", \"encode.0.conv1.weight_g\", \"encode.0.conv1.weight_v\", \"encode.0.conv2.bias\", \"encode.0.conv2.weight_g\", \"encode.0.conv2.weight_v\", \"encode.0.norm1.weight\", \"encode.0.norm1.bias\", \"encode.0.norm2.weight\", \"encode.0.norm2.bias\", \"encode.0.conv1x1.weight_g\", \"encode.0.conv1x1.weight_v\", \"encode.1.conv1.bias\", \"encode.1.conv1.weight_g\", \"encode.1.conv1.weight_v\", \"encode.1.conv2.bias\", \"encode.1.conv2.weight_g\", \"encode.1.conv2.weight_v\", \"encode.1.norm1.weight\", \"encode.1.norm1.bias\", \"encode.1.norm2.weight\", \"encode.1.norm2.bias\", \"F0_conv.0.conv1.bias\", \"F0_conv.0.conv1.weight_g\", \"F0_conv.0.conv1.weight_v\", \"F0_conv.0.conv2.bias\", \"F0_conv.0.conv2.weight_g\", \"F0_conv.0.conv2.weight_v\", \"F0_conv.0.norm1.weight\", \"F0_conv.0.norm1.bias\", \"F0_conv.0.norm2.weight\", \"F0_conv.0.norm2.bias\", \"F0_conv.0.conv1x1.weight_g\", \"F0_conv.0.conv1x1.weight_v\", \"F0_conv.0.pool.bias\", \"F0_conv.0.pool.weight_g\", \"F0_conv.0.pool.weight_v\", \"F0_conv.1.bias\", \"F0_conv.1.weight_g\", \"F0_conv.1.weight_v\", \"F0_conv.2.weight\", \"F0_conv.2.bias\", \"N_conv.0.conv1.bias\", \"N_conv.0.conv1.weight_g\", \"N_conv.0.conv1.weight_v\", \"N_conv.0.conv2.bias\", \"N_conv.0.conv2.weight_g\", \"N_conv.0.conv2.weight_v\", \"N_conv.0.norm1.weight\", \"N_conv.0.norm1.bias\", \"N_conv.0.norm2.weight\", \"N_conv.0.norm2.bias\", \"N_conv.0.conv1x1.weight_g\", \"N_conv.0.conv1x1.weight_v\", \"N_conv.0.pool.bias\", \"N_conv.0.pool.weight_g\", \"N_conv.0.pool.weight_v\", \"N_conv.1.bias\", \"N_conv.1.weight_g\", \"N_conv.1.weight_v\", \"N_conv.2.weight\", \"N_conv.2.bias\", \"asr_res.1.weight\", \"asr_res.1.bias\". \n\tsize mismatch for decode.2.conv1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decode.2.conv1.weight_g: copying a param with shape torch.Size([512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1, 1]).\n\tsize mismatch for decode.2.conv1.weight_v: copying a param with shape torch.Size([512, 1090, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1090, 3]).\n\tsize mismatch for decode.2.conv2.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1024]).\n\tsize mismatch for decode.2.conv2.weight_g: copying a param with shape torch.Size([512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1, 1]).\n\tsize mismatch for decode.2.conv2.weight_v: copying a param with shape torch.Size([512, 512, 3]) from checkpoint, the shape in current model is torch.Size([1024, 1024, 3]).\n\tsize mismatch for decode.2.norm2.fc.weight: copying a param with shape torch.Size([1024, 128]) from checkpoint, the shape in current model is torch.Size([2048, 128]).\n\tsize mismatch for decode.2.norm2.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for decode.2.conv1x1.weight_g: copying a param with shape torch.Size([512, 1, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1, 1]).\n\tsize mismatch for decode.2.conv1x1.weight_v: copying a param with shape torch.Size([512, 1090, 1]) from checkpoint, the shape in current model is torch.Size([1024, 1090, 1]).\n\tsize mismatch for decode.3.conv1.weight_v: copying a param with shape torch.Size([512, 512, 3]) from checkpoint, the shape in current model is torch.Size([512, 1090, 3]).\n\tsize mismatch for decode.3.norm1.fc.weight: copying a param with shape torch.Size([1024, 128]) from checkpoint, the shape in current model is torch.Size([2180, 128]).\n\tsize mismatch for decode.3.norm1.fc.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([2180])."
     ]
    }
   ],
   "source": [
    "# Load StyleTTS\n",
    "model_path = \"./Models/LJSpeech/epoch_2nd_00180.pth\"\n",
    "model_config_path = \"./Models/LJSpeech/config.yml\"\n",
    "\n",
    "config = yaml.safe_load(open(model_config_path))\n",
    "\n",
    "# Load pretrained ASR model\n",
    "ASR_config = config.get('ASR_config', False)\n",
    "ASR_path = config.get('ASR_path', False)\n",
    "text_aligner = load_ASR_models(ASR_path, ASR_config)\n",
    "\n",
    "# Load pretrained F0 model\n",
    "F0_path = config.get('F0_path', False)\n",
    "pitch_extractor = load_F0_models(F0_path)\n",
    "\n",
    "# ✅ Fix: Load a default BERT model since it's missing in config.yml\n",
    "from transformers import AutoModel, AutoConfig\n",
    "\n",
    "bert_model_name = \"bert-base-uncased\"  # Default BERT model\n",
    "bert_config = AutoConfig.from_pretrained(bert_model_name)\n",
    "bert = AutoModel.from_pretrained(bert_model_name, config=bert_config)\n",
    "print(config['model_params'].keys())  # Check which keys exist\n",
    "if 'decoder' not in config['model_params']:\n",
    "    print(\"⚠️ Warning: 'decoder' is missing in config! Using default settings.\")\n",
    "    config['model_params']['decoder'] = Munch({  # ✅ Convert it to Munch here\n",
    "        'type': 'hifigan',  # Default decoder type\n",
    "        'resblock_kernel_sizes': [3, 7, 11],\n",
    "        'upsample_rates': [8, 8, 2, 2],\n",
    "        'upsample_initial_channel': 512,\n",
    "        'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]],\n",
    "        'upsample_kernel_sizes': [16, 16, 4, 4],\n",
    "        'gen_istft_n_fft': 1024,\n",
    "        'gen_istft_hop_size': 256\n",
    "    })\n",
    "\n",
    "# ✅ Add default max_dur if it's missing - and set it to 1 to match pretrained model\n",
    "if 'max_dur' not in config['model_params']:\n",
    "    print(\"⚠️ Warning: 'max_dur' is missing in config! Using default value: 1 (to match pretrained model).\")\n",
    "    config['model_params']['max_dur'] = 1 # Set max_dur to 1 \n",
    "\n",
    "# ✅ Add default multispeaker if it's missing\n",
    "if 'multispeaker' not in config['model_params']:\n",
    "    print(\"⚠️ Warning: 'multispeaker' is missing in config! Using default value: False.\")\n",
    "    config['model_params']['multispeaker'] = False # Default to single speaker model\n",
    "\n",
    "# ✅ Add default diffusion config with transformer and embedding_mask_proba\n",
    "if 'diffusion' not in config['model_params']:\n",
    "    print(\"⚠️ Warning: 'diffusion' is missing in config! Using default with transformer and embedding_mask_proba.\")\n",
    "    config['model_params']['diffusion'] = Munch({\n",
    "        'transformer': Munch({ # Transformer config with default params\n",
    "            'num_layers': 2,    # Example default value, adjust as needed\n",
    "            'num_heads': 8,     # Example default value, adjust as needed\n",
    "            'head_features': 64, # Example default value, adjust as needed\n",
    "            'multiplier': 4      # Example default value, adjust as needed\n",
    "        }),\n",
    "        'dist': Munch({ # Added minimal dist config\n",
    "            'mean': 0.0,\n",
    "            'std': 1.0,\n",
    "            'sigma_data': 0.5 # Example value\n",
    "        }),\n",
    "        'embedding_mask_proba': 0.1 # ✅ Default embedding_mask_proba\n",
    "    })\n",
    "\n",
    "# ✅ Add default slm config\n",
    "if 'slm' not in config['model_params']:\n",
    "    print(\"⚠️ Warning: 'slm' is missing in config! Using default values.\")\n",
    "    config['model_params']['slm'] = Munch({\n",
    "        'hidden': 256,        # Example default hidden dimension, adjust as needed\n",
    "        'nlayers': 2,         # Example default number of layers, adjust as needed\n",
    "        'initial_channel': 512 # Example default initial channel, adjust as needed\n",
    "    })\n",
    "\n",
    "\n",
    "# Now call build_model() with the correct number of arguments\n",
    "model = build_model(Munch(config['model_params']), text_aligner, pitch_extractor, bert)\n",
    "\n",
    "# Load model parameters\n",
    "params = torch.load(model_path, map_location='cpu')\n",
    "params = params['net']\n",
    "for key in model:\n",
    "    if key in params:\n",
    "        if not \"discriminator\" in key:\n",
    "            print('%s loaded' % key)\n",
    "            model[key].load_state_dict(params[key])\n",
    "\n",
    "# Set model to evaluation mode\n",
    "_ = [model[key].eval() for key in model]\n",
    "_ = [model[key].to(device) for key in model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b803110e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Synthesize speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e8ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first 3 training sample as references\n",
    "\n",
    "train_path = config.get('train_data', None)\n",
    "val_path = config.get('val_data', None)\n",
    "train_list, val_list = get_data_path_list(train_path, val_path)\n",
    "\n",
    "ref_dicts = {}\n",
    "for j in range(3):\n",
    "    filename = train_list[j].split('|')[0]\n",
    "    name = filename.split('/')[-1].replace('.wav', '')\n",
    "    ref_dicts[name] = filename\n",
    "    \n",
    "reference_embeddings = compute_style(ref_dicts, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24655f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthesize a text\n",
    "text = ''' StyleTTS is a style-based generative model for parallel TTS that can synthesize diverse speech with natural prosody from a reference speech utterance. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e9f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "ps = global_phonemizer.phonemize([text])\n",
    "ps = word_tokenize(ps[0])\n",
    "ps = ' '.join(ps)\n",
    "tokens = textclenaer(ps)\n",
    "tokens.insert(0, 0)\n",
    "tokens.append(0)\n",
    "tokens = torch.LongTensor(tokens).to(device).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca57469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_samples = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    input_lengths = torch.LongTensor([tokens.shape[-1]]).to(device)\n",
    "    m = length_to_mask(input_lengths).to(device)\n",
    "    t_en = model.text_encoder(tokens, input_lengths, m)\n",
    "        \n",
    "    for key, (ref, _) in reference_embeddings.items():\n",
    "        \n",
    "        s = ref.squeeze(1)\n",
    "        style = s\n",
    "        \n",
    "        d = model.predictor.text_encoder(t_en, style, input_lengths, m)\n",
    "\n",
    "        x, _ = model.predictor.lstm(d)\n",
    "        duration = model.predictor.duration_proj(x)\n",
    "        pred_dur = torch.round(duration.squeeze()).clamp(min=1)\n",
    "        \n",
    "        pred_aln_trg = torch.zeros(input_lengths, int(pred_dur.sum().data))\n",
    "        c_frame = 0\n",
    "        for i in range(pred_aln_trg.size(0)):\n",
    "            pred_aln_trg[i, c_frame:c_frame + int(pred_dur[i].data)] = 1\n",
    "            c_frame += int(pred_dur[i].data)\n",
    "\n",
    "        # encode prosody\n",
    "        en = (d.transpose(-1, -2) @ pred_aln_trg.unsqueeze(0).to(device))\n",
    "        style = s.expand(en.shape[0], en.shape[1], -1)\n",
    "\n",
    "        F0_pred, N_pred = model.predictor.F0Ntrain(en, s)\n",
    "\n",
    "        out = model.decoder((t_en @ pred_aln_trg.unsqueeze(0).to(device)), \n",
    "                                F0_pred, N_pred, ref.squeeze().unsqueeze(0))\n",
    "\n",
    "\n",
    "        c = out.squeeze()\n",
    "        y_g_hat = generator(c.unsqueeze(0))\n",
    "        y_out = y_g_hat.squeeze().cpu().numpy()\n",
    "\n",
    "        c = out.squeeze()\n",
    "        y_g_hat = generator(c.unsqueeze(0))\n",
    "        y_out = y_g_hat.squeeze()\n",
    "        \n",
    "        converted_samples[key] = y_out.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d7f7d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "for key, wave in converted_samples.items():\n",
    "    print('Synthesized: %s' % key)\n",
    "    display(ipd.Audio(wave, rate=24000))\n",
    "    try:\n",
    "        print('Reference: %s' % key)\n",
    "        display(ipd.Audio(reference_embeddings[key][-1], rate=24000))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe14d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c5e82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "styletts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
